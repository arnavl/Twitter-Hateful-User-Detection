{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from src.GNN_models import GnnModel\n",
    "from src.data_partition import data_partition_fix, data_partition_random\n",
    "import random\n",
    "from src.utils import save_log_func\n",
    "import argparse\n",
    "import os\n",
    "from src.flags import flags\n",
    "import easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_path = os.path.abspath('')\n",
    "FLAGS = flags()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: hateful\n",
      "Model: BGCN\n",
      "Trial index: 0\n",
      "Data partition seed: 101\n",
      "WARNING:tensorflow:From C:\\Users\\uditi\\Desktop\\Final Year Project\\models\\BGCN\\src\\metrics.py:10: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "===================================================================\n",
      "Epoch: 0010 train_loss= 1.05823 train_acc= 0.56667 time= 4.14898\n",
      "val_loss= 1.36157 val_acc= 0.51400\n",
      "===================================================================\n",
      "Epoch: 0020 train_loss= 0.90595 train_acc= 0.56667 time= 4.14882\n",
      "val_loss= 1.54989 val_acc= 0.46200\n",
      "===================================================================\n",
      "Epoch: 0030 train_loss= 0.77154 train_acc= 0.70000 time= 4.17998\n",
      "val_loss= 1.72337 val_acc= 0.45800\n",
      "===================================================================\n",
      "Epoch: 0040 train_loss= 0.65795 train_acc= 0.73333 time= 4.15839\n",
      "val_loss= 1.83842 val_acc= 0.45600\n",
      "===================================================================\n",
      "Epoch: 0050 train_loss= 0.75709 train_acc= 0.73333 time= 4.17973\n",
      "val_loss= 2.05899 val_acc= 0.44000\n",
      "===================================================================\n",
      "Epoch: 0060 train_loss= 0.59259 train_acc= 0.76667 time= 4.14801\n",
      "val_loss= 2.52151 val_acc= 0.45400\n",
      "===================================================================\n",
      "Epoch: 0070 train_loss= 0.48274 train_acc= 0.83333 time= 4.15068\n",
      "val_loss= 2.91639 val_acc= 0.46200\n",
      "===================================================================\n",
      "Epoch: 0080 train_loss= 0.59095 train_acc= 0.83333 time= 4.19057\n",
      "val_loss= 3.55958 val_acc= 0.45400\n",
      "===================================================================\n",
      "Epoch: 0090 train_loss= 0.47943 train_acc= 0.90000 time= 4.21592\n",
      "val_loss= 3.75051 val_acc= 0.46400\n",
      "===================================================================\n",
      "Epoch: 0100 train_loss= 0.45008 train_acc= 0.83333 time= 4.28038\n",
      "val_loss= 3.77218 val_acc= 0.45000\n",
      "===================================================================\n",
      "Epoch: 0110 train_loss= 0.44335 train_acc= 0.83333 time= 4.15110\n",
      "val_loss= 4.31206 val_acc= 0.44800\n",
      "===================================================================\n",
      "Epoch: 0120 train_loss= 0.43007 train_acc= 0.86667 time= 4.15422\n",
      "val_loss= 4.77947 val_acc= 0.47000\n",
      "===================================================================\n",
      "Epoch: 0130 train_loss= 0.44899 train_acc= 0.86667 time= 4.20890\n",
      "val_loss= 4.70574 val_acc= 0.45800\n",
      "===================================================================\n",
      "Epoch: 0140 train_loss= 0.45642 train_acc= 0.83333 time= 4.17503\n",
      "val_loss= 4.57611 val_acc= 0.44600\n",
      "===================================================================\n",
      "Epoch: 0150 train_loss= 0.37535 train_acc= 0.86667 time= 4.26688\n",
      "val_loss= 4.63109 val_acc= 0.44400\n",
      "===================================================================\n",
      "Epoch: 0160 train_loss= 0.41739 train_acc= 0.90000 time= 4.30081\n",
      "val_loss= 4.87008 val_acc= 0.46400\n",
      "===================================================================\n",
      "Epoch: 0170 train_loss= 0.40734 train_acc= 0.93333 time= 4.29047\n",
      "val_loss= 5.24723 val_acc= 0.46400\n",
      "===================================================================\n",
      "Epoch: 0180 train_loss= 0.31735 train_acc= 0.93333 time= 4.50190\n",
      "val_loss= 5.83592 val_acc= 0.45800\n",
      "===================================================================\n",
      "Epoch: 0190 train_loss= 0.30901 train_acc= 0.96667 time= 4.33504\n",
      "val_loss= 5.97778 val_acc= 0.45600\n",
      "===================================================================\n",
      "Epoch: 0200 train_loss= 0.27873 train_acc= 0.93333 time= 4.27082\n",
      "val_loss= 5.84405 val_acc= 0.45000\n",
      "The test set accuracy from gcn is 0.438\n",
      "=========================start the BGCN training===================\n",
      "============================Start training the SGD-MMSBM Model========================================\n",
      "========Iteration 99=======\n",
      "The averaged perplexity on the held-out test result is 14.29400883473264\n",
      "========Iteration 199=======\n",
      "The averaged perplexity on the held-out test result is 13.075558600386017\n",
      "========Iteration 299=======\n",
      "The averaged perplexity on the held-out test result is 12.017917532019217\n",
      "========Iteration 399=======\n",
      "The averaged perplexity on the held-out test result is 11.628271958240612\n",
      "========Iteration 499=======\n",
      "The averaged perplexity on the held-out test result is 11.758739358980074\n",
      "========Iteration 599=======\n",
      "The averaged perplexity on the held-out test result is 11.718304901472065\n",
      "========Iteration 699=======\n",
      "The averaged perplexity on the held-out test result is 11.24598262158103\n",
      "========Iteration 799=======\n",
      "The averaged perplexity on the held-out test result is 11.413442947927155\n",
      "========Iteration 899=======\n",
      "The averaged perplexity on the held-out test result is 11.168290088214405\n",
      "========Iteration 999=======\n",
      "The averaged perplexity on the held-out test result is 11.17288245265882\n",
      "============================Start training the SGD-MMSBM Model========================================\n",
      "The ARI for the initial GCN (val set) is 0.010441330117735827\n",
      "The acc for the initial GCN (val set) is 0.448\n",
      "========Iteration 10099=======\n",
      "The averaged perplexity on the held-out test result is 21.330081195087683\n",
      "========Iteration 10199=======\n",
      "The averaged perplexity on the held-out test result is 20.31865904195195\n",
      "===================================================================\n",
      "Epoch: 0210 train_loss= 0.14226 train_acc= 0.96667 time= 4.31003\n",
      "val_loss= 6.40606 val_acc= 0.39400\n",
      "===================================================================\n",
      "Epoch: 0220 train_loss= 0.16839 train_acc= 0.96667 time= 4.18061\n",
      "val_loss= 7.36436 val_acc= 0.42600\n",
      "============================Start training the SGD-MMSBM Model========================================\n",
      "The ARI for the initial GCN (val set) is 0.0026957477707825793\n",
      "The acc for the initial GCN (val set) is 0.426\n",
      "========Iteration 10099=======\n",
      "The averaged perplexity on the held-out test result is 20.66473196895101\n",
      "========Iteration 10199=======\n",
      "The averaged perplexity on the held-out test result is 19.50913976106754\n",
      "===================================================================\n",
      "Epoch: 0230 train_loss= 0.35209 train_acc= 0.90000 time= 4.26687\n",
      "val_loss= 7.78753 val_acc= 0.37200\n",
      "===================================================================\n",
      "Epoch: 0240 train_loss= 0.69693 train_acc= 0.93333 time= 4.29590\n",
      "val_loss= 7.27950 val_acc= 0.37200\n",
      "============================Start training the SGD-MMSBM Model========================================\n",
      "The ARI for the initial GCN (val set) is -0.001954632587913137\n",
      "The acc for the initial GCN (val set) is 0.372\n",
      "========Iteration 10099=======\n",
      "The averaged perplexity on the held-out test result is 22.28629269547221\n",
      "========Iteration 10199=======\n",
      "The averaged perplexity on the held-out test result is 21.283493626145898\n",
      "===================================================================\n",
      "Epoch: 0250 train_loss= 1.10351 train_acc= 0.83333 time= 4.30377\n",
      "val_loss= 3.13590 val_acc= 0.42000\n",
      "===================================================================\n",
      "Epoch: 0260 train_loss= 1.03340 train_acc= 0.80000 time= 4.41326\n",
      "val_loss= 2.16034 val_acc= 0.45200\n",
      "============================Start training the SGD-MMSBM Model========================================\n",
      "The ARI for the initial GCN (val set) is -0.004517643622121094\n",
      "The acc for the initial GCN (val set) is 0.452\n",
      "========Iteration 10099=======\n",
      "The averaged perplexity on the held-out test result is 20.270587483406107\n",
      "========Iteration 10199=======\n",
      "The averaged perplexity on the held-out test result is 19.89640974377432\n",
      "===================================================================\n",
      "Epoch: 0270 train_loss= 0.64689 train_acc= 0.83333 time= 4.15683\n",
      "val_loss= 2.07200 val_acc= 0.38600\n",
      "===================================================================\n",
      "Epoch: 0280 train_loss= 1.06341 train_acc= 0.70000 time= 4.16916\n",
      "val_loss= 2.54553 val_acc= 0.21200\n",
      "============================Start training the SGD-MMSBM Model========================================\n",
      "The ARI for the initial GCN (val set) is -0.01986984092331724\n",
      "The acc for the initial GCN (val set) is 0.212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========Iteration 10099=======\n",
      "The averaged perplexity on the held-out test result is 19.363726029748364\n",
      "========Iteration 10199=======\n",
      "The averaged perplexity on the held-out test result is 18.76475597016393\n",
      "===================================================================\n",
      "Epoch: 0290 train_loss= 1.02592 train_acc= 0.63333 time= 4.21963\n",
      "val_loss= 1.88215 val_acc= 0.41600\n"
     ]
    }
   ],
   "source": [
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--dataset', type=str, default='hateful', help='which dataset to use')\n",
    "# parser.add_argument('--label_n_per_class', type=int, default=10, help='trial index')\n",
    "# parser.add_argument('--data_partition_seed', type=int, default=101,help='The seed to use split the data for trial.')\n",
    "# parser.add_argument('--trial_index', type=int, default=0, help='trial index')\n",
    "# parser.add_argument('--model_name', type=str, default='BGCN', help='which model we use for training (GCN or BGCN)')\n",
    "# parser.add_argument('--save_log', type=lambda s: s.lower() in ['true', 't', 'yes', '1'], default=False,help='Save log or not')\n",
    "# parser.add_argument('--random_partition', type=lambda s: s.lower() in ['true', 't', 'yes', '1'], default=True,\n",
    "#                         help='Save log or not')\n",
    "# parser.add_argument('--gpu', type=int, default=0, help='which gpu to use')\n",
    "\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "args = easydict.EasyDict({\n",
    "        \"dataset\": \"hateful\",\n",
    "        \"label_n_per_class\": 10,\n",
    "        \"data_partition_seed\" : 101,\n",
    "        \"trial_index\": 0,\n",
    "        \"model_name\": \"BGCN\",\n",
    "        \"save_log\": False,\n",
    "        \"random_partition\": True,\n",
    "        \"gpu\": 0\n",
    "    })\n",
    "\n",
    "\n",
    "data_partition_seed = args.data_partition_seed\n",
    "trial_index = args.trial_index\n",
    "dataset = args.dataset\n",
    "model_name = args.model_name\n",
    "save_log = args.save_log\n",
    "random_partition = args.random_partition\n",
    "label_n_per_class = args.label_n_per_class\n",
    "gpu = args.gpu\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu)\n",
    "print(\"Dataset: {}\".format(dataset))\n",
    "print(\"Model: {}\".format(model_name))\n",
    "print(\"Trial index: {}\".format(trial_index))\n",
    "print(\"Data partition seed: {}\".format(data_partition_seed))\n",
    "if save_log:\n",
    "    file_name = dataset + '_' + model_name + '_softmax_trail_' + str(trial_index) + '_random_seed_' + str(\n",
    "    data_partition_seed) + '.txt'\n",
    "    print(\"Save log mode activated, training log will be saved to /log/\" + file_name)\n",
    "\n",
    "    # ==================================Set random seed for result reproduce===============================\n",
    "\n",
    "tf.set_random_seed(data_partition_seed)\n",
    "np.random.seed(data_partition_seed)\n",
    "random.seed(data_partition_seed)\n",
    "\n",
    "    # =============================================Save log=================================================\n",
    "\n",
    "if save_log:\n",
    "    save_log_func(code_path, dataset, model_name, trial_index, data_partition_seed)\n",
    "\n",
    "    # =============================Load data=================================================\n",
    "\n",
    "dataset_dir = '../data/'\n",
    "if not random_partition:\n",
    "    adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask, labels = data_partition_fix(dataset_dir=dataset_dir, dataset_name=dataset, label_n_per_class=label_n_per_class)\n",
    "elif random_partition:\n",
    "     adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask, labels = data_partition_random(dataset_dir=dataset_dir, dataset_name=dataset, label_n_per_class=label_n_per_class)\n",
    "else:\n",
    "    \"Wrong input data format\"\n",
    "    # ==================================Train Model===========================================\n",
    "\n",
    "GNN_Model = GnnModel(FLAGS, features, labels, adj, y_train, y_val, y_test, train_mask, val_mask,test_mask, checkpt_name='model_1', model_name=model_name)\n",
    "GNN_Model.model_initialization()\n",
    "GNN_Model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
