{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uditi\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils import *\n",
    "from models import GCN, MLP,HGCN\n",
    "from coarsen import *\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')\n",
    "flags.DEFINE_string('dataset', 'hateful', 'Dataset string.')  # 'cora', 'citeseer', 'pubmed'\n",
    "flags.DEFINE_string('model', 'hgcn', 'Model string.')  # 'hgcn', 'gcn', 'gcn_cheby', 'dense'\n",
    "flags.DEFINE_float('learning_rate', 0.03, 'Initial learning rate.')\n",
    "flags.DEFINE_integer('epochs', 100, 'Number of epochs to train.')\n",
    "flags.DEFINE_integer('seed1', 123, 'random seed for numpy.')\n",
    "flags.DEFINE_integer('seed2', 123, 'random seed for tf.')\n",
    "flags.DEFINE_integer('hidden', 32, 'Number of units in hidden layer 1.')    \n",
    "flags.DEFINE_integer('node_wgt_embed_dim', 5, 'Number of units for node weight embedding.')   \n",
    "flags.DEFINE_float('dropout', 0.9, 'Dropout rate (1 - keep probability).')\n",
    "flags.DEFINE_float('weight_decay', 7e-4, 'Weight for L2 loss on embedding matrix.')\n",
    "flags.DEFINE_integer('early_stopping', 1000, 'Tolerance for early stopping (# of epochs).')\n",
    "flags.DEFINE_integer('max_degree', 3, 'Maximum Chebyshev polynomial degree.')\n",
    "flags.DEFINE_integer('coarsen_level', 4, 'Maximum coarsen level.')\n",
    "flags.DEFINE_integer('max_node_wgt', 50, 'Maximum node_wgt to avoid super-node being too large.')\n",
    "flags.DEFINE_integer('channel_num', 4, 'Number of channels')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "seed1 = FLAGS.seed1\n",
    "seed2 = FLAGS.seed2\n",
    "np.random.seed(seed1)\n",
    "tf.set_random_seed(seed2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask = load_data(FLAGS.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total nodes: 7315\n"
     ]
    }
   ],
   "source": [
    "# Some preprocessing\n",
    "features = preprocess_features(features)\n",
    "if FLAGS.model == 'gcn': \n",
    "    support = [preprocess_adj(adj)]  # Not used\n",
    "    num_supports = 1\n",
    "    model_func = GCN\n",
    "elif FLAGS.model == 'gcn_cheby':\n",
    "    support = chebyshev_polynomials(adj, FLAGS.max_degree)  # Not used\n",
    "    num_supports = 1 + FLAGS.max_degree\n",
    "    model_func = GCN\n",
    "elif FLAGS.model == 'dense':\n",
    "    support = [preprocess_adj(adj)]  # Not used\n",
    "    num_supports = 1\n",
    "    model_func = MLP\n",
    "elif FLAGS.model == 'hgcn':\n",
    "    support = [preprocess_adj(adj)]  \n",
    "    num_supports = 1\n",
    "    model_func = HGCN    \n",
    "else:\n",
    "    raise ValueError('Invalid argument for model: ' + str(FLAGS.model))\n",
    "\n",
    "graph, mapping = read_graph_from_adj(adj, FLAGS.dataset)\n",
    "print('total nodes:', graph.node_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5838 nodes in the 1 coarsened graph\n",
      "There are 4922 nodes in the 2 coarsened graph\n",
      "There are 4313 nodes in the 3 coarsened graph\n",
      "There are 3918 nodes in the 4 coarsened graph\n",
      "\n",
      "\n",
      "layer_index  1\n",
      "input shape:    (7315, 320)\n"
     ]
    }
   ],
   "source": [
    "# Step-1: Graph Coarsening.\n",
    "original_graph = graph\n",
    "transfer_list = []\n",
    "adj_list = [copy.copy(graph.A)]\n",
    "node_wgt_list = [copy.copy(graph.node_wgt)]\n",
    "for i in range(FLAGS.coarsen_level):\n",
    "    match, coarse_graph_size = generate_hybrid_matching(FLAGS.max_node_wgt, graph)\n",
    "    coarse_graph = create_coarse_graph(graph, match, coarse_graph_size)\n",
    "    transfer_list.append(copy.copy(graph.C))\n",
    "    graph = coarse_graph\n",
    "    adj_list.append(copy.copy(graph.A))  \n",
    "    node_wgt_list.append(copy.copy(graph.node_wgt))\n",
    "    print('There are %d nodes in the %d coarsened graph' %(graph.node_num, i+1))\n",
    "    \n",
    "print(\"\\n\")\n",
    "print('layer_index ', 1)\n",
    "print('input shape:   ', features[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape:     [5838, 32]\n",
      "layer_index  2\n",
      "input shape:    [5838, 32]\n",
      "output shape:     [4922, 32]\n",
      "layer_index  3\n",
      "input shape:    [4922, 32]\n",
      "output shape:     [4313, 32]\n",
      "layer_index  4\n",
      "input shape:    [4313, 32]\n",
      "output shape:     [3918, 32]\n",
      "layer_index  5\n",
      "input shape:    [3918, 32]\n",
      "output shape:     [4313, 32]\n",
      "layer_index  6\n",
      "input shape:    [4313, 32]\n",
      "output shape:     [4922, 32]\n",
      "layer_index  7\n",
      "input shape:    [4922, 32]\n",
      "output shape:     [5838, 32]\n",
      "layer_index  8\n",
      "input shape:    [5838, 32]\n",
      "output shape:     [7315, 32]\n",
      "layer_index  9\n",
      "input shape:    [7315, 32]\n",
      "output shape:     [7315, 3]\n",
      "WARNING:tensorflow:From C:\\Users\\uditi\\Desktop\\Final Year Project\\models\\H-GCN\\metrics.py:6: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(adj_list)):\n",
    "    adj_list[i] = [preprocess_adj(adj_list[i])]\n",
    "\n",
    "# Define placeholders\n",
    "placeholders = {\n",
    "    'features': tf.sparse_placeholder(tf.float32, shape=tf.constant(features[2], dtype=tf.int64)),\n",
    "    'labels': tf.placeholder(tf.float32, shape=(None, y_train.shape[1])),\n",
    "    'labels_mask': tf.placeholder(tf.int32),\n",
    "    'dropout': tf.placeholder_with_default(0., shape=()),\n",
    "    'num_features_nonzero': tf.placeholder(tf.int32)  # helper variable for sparse dropout\n",
    "}\n",
    "\n",
    "# Create model\n",
    "model = model_func(placeholders, input_dim=features[2][1], logging=True, transfer_list = transfer_list, adj_list = adj_list, node_wgt_list = node_wgt_list)\n",
    "\n",
    "# Initialize session\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model evaluation function\n",
    "def evaluate(features, labels, mask, placeholders):\n",
    "    t_test = time.time()\n",
    "    feed_dict_val = construct_feed_dict(features, labels, mask, placeholders)\n",
    "    outs_val = sess.run([model.loss, model.accuracy], feed_dict=feed_dict_val)\n",
    "    return outs_val[0], outs_val[1], (time.time() - t_test)\n",
    "\n",
    "# Init variables\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "cost_val = []\n",
    "acc_val = []\n",
    "\n",
    "\n",
    "cost_train = []\n",
    "acc_train = []\n",
    "\n",
    "cost_test = []\n",
    "acc_test = []\n",
    "best_fcn = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train_loss= 229.97504 train_acc= 0.32516 val_loss= 1.51765 val_acc= 0.46400 test_acc= 0.56967 time= 2.83311       best test_acc= 0.56967\n",
      "Epoch: 0002 train_loss= 52.73110 train_acc= 0.44756 val_loss= 1.55825 val_acc= 0.46200 test_acc= 0.57889 time= 1.80510       best test_acc= 0.57889\n",
      "Epoch: 0003 train_loss= 10.09617 train_acc= 0.49862 val_loss= 1.60707 val_acc= 0.46600 test_acc= 0.58197 time= 1.75042       best test_acc= 0.58197\n",
      "Epoch: 0004 train_loss= 11.63850 train_acc= 0.53116 val_loss= 1.66016 val_acc= 0.46400 test_acc= 0.58504 time= 1.74035       best test_acc= 0.58504\n",
      "Epoch: 0005 train_loss= 5.92467 train_acc= 0.52941 val_loss= 1.71398 val_acc= 0.46400 test_acc= 0.58607 time= 1.73197       best test_acc= 0.58607\n",
      "Epoch: 0006 train_loss= 5.69362 train_acc= 0.53442 val_loss= 1.76373 val_acc= 0.46600 test_acc= 0.58709 time= 1.79435       best test_acc= 0.58709\n",
      "Epoch: 0007 train_loss= 4.66948 train_acc= 0.52966 val_loss= 1.81008 val_acc= 0.47200 test_acc= 0.58607 time= 1.80566       best test_acc= 0.58709\n",
      "Epoch: 0008 train_loss= 4.78408 train_acc= 0.53016 val_loss= 1.84995 val_acc= 0.47800 test_acc= 0.58197 time= 1.78030       best test_acc= 0.58709\n",
      "Epoch: 0009 train_loss= 3.78848 train_acc= 0.52265 val_loss= 1.88550 val_acc= 0.47000 test_acc= 0.57992 time= 1.79425       best test_acc= 0.58709\n",
      "Epoch: 0010 train_loss= 4.08404 train_acc= 0.51189 val_loss= 1.91720 val_acc= 0.48000 test_acc= 0.57275 time= 1.69761       best test_acc= 0.58709\n",
      "Epoch: 0011 train_loss= 4.87754 train_acc= 0.50163 val_loss= 1.94541 val_acc= 0.49000 test_acc= 0.57172 time= 1.71650       best test_acc= 0.58709\n",
      "Epoch: 0012 train_loss= 4.72147 train_acc= 0.50438 val_loss= 1.96966 val_acc= 0.49600 test_acc= 0.55738 time= 1.74527       best test_acc= 0.58709\n",
      "Epoch: 0013 train_loss= 4.49975 train_acc= 0.49587 val_loss= 1.99039 val_acc= 0.49200 test_acc= 0.54816 time= 1.85587       best test_acc= 0.58709\n",
      "Epoch: 0014 train_loss= 5.43158 train_acc= 0.47409 val_loss= 2.00900 val_acc= 0.49200 test_acc= 0.53586 time= 1.78197       best test_acc= 0.58709\n",
      "Epoch: 0015 train_loss= 5.11159 train_acc= 0.46808 val_loss= 2.02383 val_acc= 0.49800 test_acc= 0.52766 time= 1.78612       best test_acc= 0.58709\n",
      "Epoch: 0016 train_loss= 7.82178 train_acc= 0.48360 val_loss= 2.03474 val_acc= 0.49000 test_acc= 0.50615 time= 1.70349       best test_acc= 0.58709\n",
      "Epoch: 0017 train_loss= 3.75913 train_acc= 0.48010 val_loss= 2.04384 val_acc= 0.49200 test_acc= 0.49795 time= 1.91859       best test_acc= 0.58709\n",
      "Epoch: 0018 train_loss= 3.74501 train_acc= 0.46883 val_loss= 2.05228 val_acc= 0.48800 test_acc= 0.49283 time= 1.93770       best test_acc= 0.58709\n",
      "Epoch: 0019 train_loss= 4.43858 train_acc= 0.47484 val_loss= 2.05935 val_acc= 0.49200 test_acc= 0.48873 time= 2.16468       best test_acc= 0.58709\n",
      "Epoch: 0020 train_loss= 5.22673 train_acc= 0.47935 val_loss= 2.06546 val_acc= 0.49000 test_acc= 0.48770 time= 2.06155       best test_acc= 0.58709\n",
      "Epoch: 0021 train_loss= 3.52105 train_acc= 0.47835 val_loss= 2.07115 val_acc= 0.49000 test_acc= 0.49795 time= 2.00025       best test_acc= 0.58709\n",
      "Epoch: 0022 train_loss= 3.41845 train_acc= 0.47459 val_loss= 2.07672 val_acc= 0.48600 test_acc= 0.49078 time= 2.27064       best test_acc= 0.58709\n",
      "Epoch: 0023 train_loss= 4.52423 train_acc= 0.47034 val_loss= 2.08222 val_acc= 0.49200 test_acc= 0.49385 time= 1.72650       best test_acc= 0.58709\n",
      "Epoch: 0024 train_loss= 4.89460 train_acc= 0.46959 val_loss= 2.08673 val_acc= 0.49000 test_acc= 0.49795 time= 1.70783       best test_acc= 0.58709\n",
      "Epoch: 0025 train_loss= 4.82459 train_acc= 0.48636 val_loss= 2.09137 val_acc= 0.48400 test_acc= 0.51229 time= 1.85075       best test_acc= 0.58709\n",
      "Epoch: 0026 train_loss= 4.19033 train_acc= 0.47459 val_loss= 2.09667 val_acc= 0.48200 test_acc= 0.52664 time= 2.69957       best test_acc= 0.58709\n",
      "Epoch: 0027 train_loss= 3.92819 train_acc= 0.49962 val_loss= 2.10183 val_acc= 0.46600 test_acc= 0.52357 time= 2.44585       best test_acc= 0.58709\n",
      "Epoch: 0028 train_loss= 3.83763 train_acc= 0.49236 val_loss= 2.10599 val_acc= 0.45800 test_acc= 0.52664 time= 2.29869       best test_acc= 0.58709\n",
      "Epoch: 0029 train_loss= 3.28506 train_acc= 0.48385 val_loss= 2.10928 val_acc= 0.46200 test_acc= 0.52766 time= 2.47065       best test_acc= 0.58709\n",
      "Epoch: 0030 train_loss= 3.50370 train_acc= 0.49412 val_loss= 2.11121 val_acc= 0.45800 test_acc= 0.53074 time= 1.95549       best test_acc= 0.58709\n",
      "Epoch: 0031 train_loss= 4.40095 train_acc= 0.49412 val_loss= 2.11196 val_acc= 0.44800 test_acc= 0.53176 time= 1.89821       best test_acc= 0.58709\n",
      "Epoch: 0032 train_loss= 3.89007 train_acc= 0.50388 val_loss= 2.11135 val_acc= 0.45200 test_acc= 0.53176 time= 1.91199       best test_acc= 0.58709\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-8390cba6f4b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# Test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mtest_cost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_duration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplaceholders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mcost_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0macc_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-faa9ffce4b7e>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(features, labels, mask, placeholders)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mt_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mfeed_dict_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconstruct_feed_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplaceholders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mouts_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mouts_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "for epoch in range(FLAGS.epochs):\n",
    "\n",
    "    t = time.time()\n",
    "    # Construct feed dictionary\n",
    "    feed_dict = construct_feed_dict(features,  y_train, train_mask, placeholders)\n",
    "    feed_dict.update({placeholders['dropout']: FLAGS.dropout})\n",
    "\n",
    "    # Training step\n",
    "    outs = sess.run([model.opt_op, model.loss, model.accuracy], feed_dict=feed_dict)\n",
    "\n",
    "\n",
    "    # Validation\n",
    "    cost, acc, duration = evaluate(features, y_val, val_mask, placeholders)\n",
    "    cost_val.append(cost)\n",
    "    \n",
    "    # Test\n",
    "    test_cost, test_acc, test_duration = evaluate(features, y_test, test_mask, placeholders)\n",
    "    cost_train.append(outs[1])\n",
    "    acc_train.append(outs[2])    \n",
    "    cost_test.append(test_cost)\n",
    "    acc_test.append(test_acc)\n",
    "    acc_val.append(acc)\n",
    "    if test_acc > best_fcn:\n",
    "        best_fcn = test_acc\n",
    "\n",
    "    # Print results\n",
    "    print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(outs[1]),\n",
    "          \"train_acc=\", \"{:.5f}\".format(outs[2]), \"val_loss=\", \"{:.5f}\".format(cost),\n",
    "          \"val_acc=\", \"{:.5f}\".format(acc), \"test_acc=\", \"{:.5f}\".format(test_acc), \"time=\", \"{:.5f}\".format(time.time() - t),\"      best test_acc=\", \"{:.5f}\".format(best_fcn),)\n",
    "\n",
    "    if epoch > FLAGS.early_stopping and cost_val[-1] > np.mean(cost_val[-(FLAGS.early_stopping+1):-1]):\n",
    "        print(\"Early stopping...\")\n",
    "        break\n",
    "\n",
    "print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### test acc for every epoch\n",
    "mat = np.array(acc_test)\n",
    "# print(np.max(mat))\n",
    "\n",
    "if FLAGS.dataset == 'cora':\n",
    "    val_index_best =  np.argmin(np.array(cost_val))\n",
    "    print('best epoch:   ',val_index_best)\n",
    "    print('test result:  ',mat[val_index_best])\n",
    "\n",
    "elif FLAGS.dataset == 'citeseer' or FLAGS.dataset == 'pubmed':\n",
    "    val_index_best =  np.argmax(np.array(acc_val))\n",
    "    print('best epoch:   ',val_index_best)\n",
    "    print('test result:  ',mat[val_index_best])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
