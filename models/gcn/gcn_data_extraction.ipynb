{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import pickle\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/'\n",
    "x = []\n",
    "y = []\n",
    "test_index = []\n",
    "test_mask = []\n",
    "train_labeled_mask = []\n",
    "\n",
    "labeled_index = []\n",
    "labeled_mask = []\n",
    "all_mask = []\n",
    "original_graph = defaultdict(list)\n",
    "graph = defaultdict(list)\n",
    "\n",
    "h = 0\n",
    "n = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('../../data/','users.edges')) as edges_f:\n",
    "    for line in edges_f:\n",
    "        s, e = line.split()\n",
    "        original_graph[int(s)].append(int(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================== 7315\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join('../../data/','users_hate_all.content')) as content_f:\n",
    "    for line in content_f:\n",
    "        line = line.split()\n",
    "        x.append([float(i) for i in line[1:-1]])\n",
    "        labeled_mask.append(line[-1] != 'other')\n",
    "        if line[-1] != 'other':\n",
    "            all_mask.append(True)\n",
    "        else:\n",
    "            flg = False\n",
    "            for user in original_graph[int(line[0])]:\n",
    "                if user < len(labeled_mask) and labeled_mask[user] and random.random() < 0.05:#0.001:\n",
    "                    all_mask.append(True)\n",
    "                    flg = True\n",
    "                    break\n",
    "            if not flg:\n",
    "                all_mask.append(False)\n",
    "\n",
    "        if line[-1] != 'other':\n",
    "            labeled_index.append(int(line[0]))\n",
    "        if line[-1] != 'other' and random.random() < 0.2:\n",
    "            test_index.append(len(labeled_index))\n",
    "            test_mask.append(True)\n",
    "            train_labeled_mask.append(False)\n",
    "            \n",
    "        else:\n",
    "            test_mask.append(False)\n",
    "            train_labeled_mask.append(line[-1] != 'other')\n",
    "        #label = 1 if line[-1] == 'hateful' else 0\n",
    "        label = []\n",
    "        if line[-1] == 'hateful':\n",
    "            label = [1, 0, 0]\n",
    "        elif line[-1] == 'normal':\n",
    "            label = [0, 1, 0]\n",
    "        else:\n",
    "            label = [0, 0, 1]\n",
    "        y.append(label)\n",
    "print('====================================', sum(all_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================== 7315\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join('../../data/','users.edges')) as edges_f:\n",
    "    for line in edges_f:\n",
    "        s, e = line.split()\n",
    "        ## fully-supervised\n",
    "        if not (all_mask[int(s)] and all_mask[int(e)]):\n",
    "            continue\n",
    "        new_s = sum(all_mask[:int(s)])\n",
    "        new_e = sum(all_mask[:int(e)])\n",
    "        graph[new_s].append(new_e)\n",
    "\n",
    "print('====================================', len(graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "test_index = np.array(test_index, dtype=np.int32)\n",
    "test_mask = np.array(test_mask)\n",
    "train_labeled_mask = np.array(train_labeled_mask)\n",
    "labeled_index = np.array(labeled_index)\n",
    "labeled_mask = np.array(labeled_mask)\n",
    "all_mask = np.array(all_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size:6339 976 3995\n"
     ]
    }
   ],
   "source": [
    "#semi-supervised\n",
    "# all_x = x[~test_mask]\n",
    "# all_y = y[~test_mask]\n",
    "#fully-supervised\n",
    "all_x = x[all_mask & ~test_mask]\n",
    "all_y = y[all_mask & ~test_mask]\n",
    "test_x = x[test_mask]\n",
    "test_y = y[test_mask]\n",
    "train_x = x[train_labeled_mask]\n",
    "train_y = y[train_labeled_mask]\n",
    "print(\"size:{} {} {}\".format(len(all_x), len(test_x),len(train_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_x_f = open(os.path.join(path,'ind.hateful.allx'), 'wb')\n",
    "pickle.dump(all_x, all_x_f)\n",
    "all_x_f.close()\n",
    "all_y_f = open(os.path.join(path,'ind.hateful.ally'), 'wb')\n",
    "pickle.dump(all_y, all_y_f)\n",
    "all_y_f.close()\n",
    "\n",
    "graph_f = open(os.path.join(path,'ind.hateful.graph'), 'wb')\n",
    "pickle.dump(graph, graph_f)\n",
    "graph_f.close()\n",
    "\n",
    "test_index_f = open(os.path.join(path,'ind.hateful.test.index'), 'w')\n",
    "#np.savetxt(\"ind.hateful.test.index'\", test_index, newline=\"\\n\")\n",
    "test_index_f.write('\\n'.join(map(str, test_index)))\n",
    "#pickle.dump(test_index, test_index_f)\n",
    "test_index_f.close()\n",
    "\n",
    "test_x_f = open(os.path.join(path,'ind.hateful.tx'), 'wb')\n",
    "pickle.dump(test_x, test_x_f)\n",
    "test_x_f.close()\n",
    "test_y_f = open(os.path.join(path,'ind.hateful.ty'), 'wb')\n",
    "pickle.dump(test_y, test_y_f)\n",
    "test_y_f.close()\n",
    "train_x_f = open(os.path.join(path,'ind.hateful.x'), 'wb')\n",
    "pickle.dump(train_x, train_x_f)\n",
    "train_x_f.close()\n",
    "train_y_f = open(os.path.join(path,'ind.hateful.y'), 'wb')\n",
    "pickle.dump(train_y, train_y_f)\n",
    "train_y_f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
