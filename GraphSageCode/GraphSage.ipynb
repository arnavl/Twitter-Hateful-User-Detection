{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uditi\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data, Dataset, InMemoryDataset, NeighborSampler\n",
    "from torch_geometric.nn import SAGEConv, GATConv\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from data_preprocess_gnn import construct_dataset, get_labeled_index\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, confusion_matrix, recall_score, f1_score, auc, accuracy_score, precision_score\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from torch.nn import init\n",
    "import argparse\n",
    "import easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullySupervisedGraphSageModel(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(FullySupervisedGraphSageModel, self).__init__()\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        self.conv_layers.append(SAGEConv(num_features, 256))\n",
    "        #self.conv_layers.append(SAGEConv(256, 256))\n",
    "        self.classify_layer = nn.Linear(256, 3)\n",
    "        init.xavier_uniform_(self.classify_layer.weight)\n",
    "        init.xavier_uniform_(self.conv_layers[0].weight)\n",
    "\n",
    "    def forward(self, x, data_flow):\n",
    "        data = data_flow[0]\n",
    "        x = x[data.n_id]\n",
    "        x = self.conv_layers[0](x, data.edge_index, size=data.size)\n",
    "        # data = data_flow[1]\n",
    "        # x = self.conv_layers[1](x, data.edge_index, size=data.size)\n",
    "        scores = self.classify_layer(x)\n",
    "        return F.log_softmax(scores, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FullySupervisedGATModel(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(FullySupervisedGATModel, self).__init__()\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        self.conv_layers.append(GATConv(num_features, 256))\n",
    "        #self.conv_layers.append(SAGEConv(256, 256))\n",
    "        self.classify_layer = nn.Linear(256, 3)\n",
    "        init.xavier_uniform_(self.classify_layer.weight)\n",
    "        init.xavier_uniform_(self.conv_layers[0].weight)\n",
    "\n",
    "\n",
    "    def forward(self, x, data_flow):\n",
    "        block = data_flow[0]\n",
    "        x = x[block.n_id]\n",
    "        x = self.conv_layers[0]((x, x[block.res_n_id].squeeze()), block.edge_index, size=block.size)\n",
    "        # data = data_flow[1]\n",
    "        # x = self.conv_layers[1](x, data.edge_index, size=data.size)\n",
    "        scores = self.classify_layer(x)\n",
    "        return F.log_softmax(scores, dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader, data, model, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data_flow in loader(data.train_mask):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data_flow)\n",
    "        loss = F.nll_loss(out, data.y[data_flow.n_id], weight=torch.FloatTensor([1, 0 , 10]))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * data_flow.batch_size\n",
    "    return total_loss / (data.train_mask==True).sum().item()\n",
    "\n",
    "def test(loader, data, model, mask):\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    correct = 0\n",
    "    for data_flow in loader(mask):\n",
    "        pred = model(data.x, data_flow).max(1)[1]\n",
    "        correct += pred.eq(data.y[data_flow.n_id]).sum().item()\n",
    "        y_pred.extend([1 if v == 2 else 0 for v in pred])\n",
    "        y_true.extend([1 if v == 2 else 0 for v in data.y[data_flow.n_id]])\n",
    "    return correct / (mask==True).sum().item(), y_pred, y_true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====information of experiment====\n",
      "FEATURE:  all classification_type: hate MODEL: sage\n",
      "====end information of experiment====\n",
      "========begin trail 0===========\n",
      "Trail: 0, Epoch: 00, Loss: 0.7707\n",
      "[[586 300]\n",
      " [ 13  96]]\n",
      "Fscore: 0.3801980198019802 Recall: 0.8807339449541285 Precision: 0.24242424242424243 Test: 0.628140703517588\n",
      "Trail: 0, Epoch: 01, Loss: 0.5453\n",
      "Trail: 0, Epoch: 02, Loss: 0.5018\n",
      "Trail: 0, Epoch: 03, Loss: 0.4739\n",
      "Trail: 0, Epoch: 04, Loss: 0.4544\n",
      "Trail: 0, Epoch: 05, Loss: 0.4495\n",
      "Trail: 0, Epoch: 06, Loss: 0.4312\n",
      "Trail: 0, Epoch: 07, Loss: 0.4266\n",
      "Trail: 0, Epoch: 08, Loss: 0.4193\n",
      "Trail: 0, Epoch: 09, Loss: 0.4141\n",
      "Trail: 0, Epoch: 10, Loss: 0.4157\n",
      "Trail: 0, Epoch: 11, Loss: 0.4145\n",
      "Trail: 0, Epoch: 12, Loss: 0.4062\n",
      "Trail: 0, Epoch: 13, Loss: 0.4025\n",
      "Trail: 0, Epoch: 14, Loss: 0.4010\n",
      "Trail: 0, Epoch: 15, Loss: 0.4021\n",
      "Trail: 0, Epoch: 16, Loss: 0.3938\n",
      "Trail: 0, Epoch: 17, Loss: 0.3979\n",
      "Trail: 0, Epoch: 18, Loss: 0.3861\n",
      "Trail: 0, Epoch: 19, Loss: 0.3833\n",
      "Trail: 0, Epoch: 20, Loss: 0.3831\n",
      "Trail: 0, Epoch: 21, Loss: 0.3821\n",
      "Trail: 0, Epoch: 22, Loss: 0.3798\n",
      "Trail: 0, Epoch: 23, Loss: 0.3817\n",
      "Trail: 0, Epoch: 24, Loss: 0.3746\n",
      "Trail: 0, Epoch: 25, Loss: 0.3780\n",
      "Trail: 0, Epoch: 26, Loss: 0.3735\n",
      "Trail: 0, Epoch: 27, Loss: 0.3668\n",
      "Trail: 0, Epoch: 28, Loss: 0.3688\n",
      "Trail: 0, Epoch: 29, Loss: 0.3738\n",
      "Trail: 0, Epoch: 30, Loss: 0.3696\n",
      "Trail: 0, Epoch: 31, Loss: 0.3615\n",
      "Trail: 0, Epoch: 32, Loss: 0.3723\n",
      "Trail: 0, Epoch: 33, Loss: 0.3619\n",
      "Trail: 0, Epoch: 34, Loss: 0.3644\n",
      "Trail: 0, Epoch: 35, Loss: 0.3670\n",
      "Trail: 0, Epoch: 36, Loss: 0.3606\n",
      "Trail: 0, Epoch: 37, Loss: 0.3580\n",
      "Trail: 0, Epoch: 38, Loss: 0.3568\n",
      "Trail: 0, Epoch: 39, Loss: 0.3560\n",
      "Trail: 0, Epoch: 40, Loss: 0.3735\n",
      "Trail: 0, Epoch: 41, Loss: 0.3602\n",
      "Trail: 0, Epoch: 42, Loss: 0.3540\n",
      "Trail: 0, Epoch: 43, Loss: 0.3554\n",
      "Trail: 0, Epoch: 44, Loss: 0.3586\n",
      "Trail: 0, Epoch: 45, Loss: 0.3529\n",
      "Trail: 0, Epoch: 46, Loss: 0.3586\n",
      "Trail: 0, Epoch: 47, Loss: 0.3593\n",
      "Trail: 0, Epoch: 48, Loss: 0.3510\n",
      "Trail: 0, Epoch: 49, Loss: 0.3525\n",
      "Trail: 0, Epoch: 50, Loss: 0.3538\n",
      "[[817  69]\n",
      " [ 39  70]]\n",
      "Fscore: 0.564516129032258 Recall: 0.6422018348623854 Precision: 0.5035971223021583 Test: 0.8894472361809045\n",
      "Trail: 0, Epoch: 51, Loss: 0.3652\n",
      "Trail: 0, Epoch: 52, Loss: 0.3517\n",
      "Trail: 0, Epoch: 53, Loss: 0.3507\n",
      "Trail: 0, Epoch: 54, Loss: 0.3556\n",
      "Trail: 0, Epoch: 55, Loss: 0.3514\n",
      "Trail: 0, Epoch: 56, Loss: 0.3448\n",
      "Trail: 0, Epoch: 57, Loss: 0.3468\n",
      "Trail: 0, Epoch: 58, Loss: 0.3493\n",
      "Trail: 0, Epoch: 59, Loss: 0.3464\n",
      "Trail: 0, Epoch: 60, Loss: 0.3429\n",
      "Trail: 0, Epoch: 61, Loss: 0.3489\n",
      "Trail: 0, Epoch: 62, Loss: 0.3680\n",
      "Trail: 0, Epoch: 63, Loss: 0.3404\n",
      "Trail: 0, Epoch: 64, Loss: 0.3389\n",
      "Trail: 0, Epoch: 65, Loss: 0.3379\n",
      "Trail: 0, Epoch: 66, Loss: 0.3356\n",
      "Trail: 0, Epoch: 67, Loss: 0.3406\n",
      "Trail: 0, Epoch: 68, Loss: 0.3432\n",
      "Trail: 0, Epoch: 69, Loss: 0.3409\n",
      "Trail: 0, Epoch: 70, Loss: 0.3446\n",
      "Trail: 0, Epoch: 71, Loss: 0.3377\n",
      "Trail: 0, Epoch: 72, Loss: 0.3435\n",
      "Trail: 0, Epoch: 73, Loss: 0.3485\n",
      "Trail: 0, Epoch: 74, Loss: 0.3423\n",
      "Trail: 0, Epoch: 75, Loss: 0.3373\n",
      "Trail: 0, Epoch: 76, Loss: 0.3378\n",
      "Trail: 0, Epoch: 77, Loss: 0.3368\n",
      "Trail: 0, Epoch: 78, Loss: 0.3398\n",
      "Trail: 0, Epoch: 79, Loss: 0.3408\n",
      "Trail: 0, Epoch: 80, Loss: 0.3377\n",
      "Trail: 0, Epoch: 81, Loss: 0.3366\n",
      "Trail: 0, Epoch: 82, Loss: 0.3347\n",
      "Trail: 0, Epoch: 83, Loss: 0.3323\n",
      "Trail: 0, Epoch: 84, Loss: 0.3373\n",
      "Trail: 0, Epoch: 85, Loss: 0.3366\n",
      "Trail: 0, Epoch: 86, Loss: 0.3390\n",
      "Trail: 0, Epoch: 87, Loss: 0.3336\n",
      "Trail: 0, Epoch: 88, Loss: 0.3385\n",
      "Trail: 0, Epoch: 89, Loss: 0.3379\n",
      "Trail: 0, Epoch: 90, Loss: 0.3386\n",
      "Trail: 0, Epoch: 91, Loss: 0.3336\n",
      "Trail: 0, Epoch: 92, Loss: 0.3325\n",
      "Trail: 0, Epoch: 93, Loss: 0.3402\n",
      "Trail: 0, Epoch: 94, Loss: 0.3424\n",
      "Trail: 0, Epoch: 95, Loss: 0.3383\n",
      "Trail: 0, Epoch: 96, Loss: 0.3381\n",
      "Trail: 0, Epoch: 97, Loss: 0.3315\n",
      "Trail: 0, Epoch: 98, Loss: 0.3384\n",
      "Trail: 0, Epoch: 99, Loss: 0.3329\n",
      "Trail: 0, Epoch: 100, Loss: 0.3339\n",
      "[[777 109]\n",
      " [ 24  85]]\n",
      "Fscore: 0.5610561056105611 Recall: 0.7798165137614679 Precision: 0.4381443298969072 Test: 0.8653266331658291\n",
      "Trail: 0, Epoch: 101, Loss: 0.3347\n",
      "Trail: 0, Epoch: 102, Loss: 0.3331\n",
      "Trail: 0, Epoch: 103, Loss: 0.3288\n",
      "Trail: 0, Epoch: 104, Loss: 0.3457\n",
      "Trail: 0, Epoch: 105, Loss: 0.3384\n",
      "Trail: 0, Epoch: 106, Loss: 0.3338\n",
      "Trail: 0, Epoch: 107, Loss: 0.3348\n",
      "Trail: 0, Epoch: 108, Loss: 0.3328\n",
      "Trail: 0, Epoch: 109, Loss: 0.3387\n",
      "Trail: 0, Epoch: 110, Loss: 0.3326\n",
      "Trail: 0, Epoch: 111, Loss: 0.3322\n",
      "Trail: 0, Epoch: 112, Loss: 0.3356\n",
      "Trail: 0, Epoch: 113, Loss: 0.3442\n",
      "Trail: 0, Epoch: 114, Loss: 0.3317\n",
      "Trail: 0, Epoch: 115, Loss: 0.3301\n",
      "Trail: 0, Epoch: 116, Loss: 0.3397\n",
      "Trail: 0, Epoch: 117, Loss: 0.3401\n",
      "Trail: 0, Epoch: 118, Loss: 0.3263\n",
      "Trail: 0, Epoch: 119, Loss: 0.3239\n",
      "Trail: 0, Epoch: 120, Loss: 0.3262\n",
      "Trail: 0, Epoch: 121, Loss: 0.3291\n",
      "Trail: 0, Epoch: 122, Loss: 0.3312\n",
      "Trail: 0, Epoch: 123, Loss: 0.3306\n",
      "Trail: 0, Epoch: 124, Loss: 0.3248\n",
      "Trail: 0, Epoch: 125, Loss: 0.3329\n",
      "Trail: 0, Epoch: 126, Loss: 0.3301\n",
      "Trail: 0, Epoch: 127, Loss: 0.3287\n",
      "Trail: 0, Epoch: 128, Loss: 0.3276\n",
      "Trail: 0, Epoch: 129, Loss: 0.3270\n",
      "Trail: 0, Epoch: 130, Loss: 0.3251\n",
      "Trail: 0, Epoch: 131, Loss: 0.3221\n",
      "Trail: 0, Epoch: 132, Loss: 0.3268\n",
      "Trail: 0, Epoch: 133, Loss: 0.3262\n",
      "Trail: 0, Epoch: 134, Loss: 0.3247\n",
      "Trail: 0, Epoch: 135, Loss: 0.3248\n",
      "Trail: 0, Epoch: 136, Loss: 0.3466\n",
      "Trail: 0, Epoch: 137, Loss: 0.3243\n",
      "Trail: 0, Epoch: 138, Loss: 0.3262\n",
      "Trail: 0, Epoch: 139, Loss: 0.3187\n",
      "Trail: 0, Epoch: 140, Loss: 0.3309\n",
      "Trail: 0, Epoch: 141, Loss: 0.3288\n",
      "Trail: 0, Epoch: 142, Loss: 0.3220\n",
      "Trail: 0, Epoch: 143, Loss: 0.3376\n",
      "Trail: 0, Epoch: 144, Loss: 0.3177\n",
      "Trail: 0, Epoch: 145, Loss: 0.3226\n",
      "Trail: 0, Epoch: 146, Loss: 0.3244\n",
      "Trail: 0, Epoch: 147, Loss: 0.3321\n",
      "Trail: 0, Epoch: 148, Loss: 0.3256\n",
      "Trail: 0, Epoch: 149, Loss: 0.3331\n",
      "Trail: 0, Epoch: 150, Loss: 0.3203\n",
      "[[786 100]\n",
      " [ 28  81]]\n",
      "Fscore: 0.5586206896551724 Recall: 0.7431192660550459 Precision: 0.44751381215469616 Test: 0.8703517587939699\n",
      "Trail: 0, Epoch: 151, Loss: 0.3241\n",
      "Trail: 0, Epoch: 152, Loss: 0.3244\n",
      "Trail: 0, Epoch: 153, Loss: 0.3227\n",
      "Trail: 0, Epoch: 154, Loss: 0.3317\n",
      "Trail: 0, Epoch: 155, Loss: 0.3226\n",
      "Trail: 0, Epoch: 156, Loss: 0.3245\n",
      "Trail: 0, Epoch: 157, Loss: 0.4308\n",
      "Trail: 0, Epoch: 158, Loss: 0.3422\n",
      "Trail: 0, Epoch: 159, Loss: 0.3350\n",
      "Trail: 0, Epoch: 160, Loss: 0.3286\n",
      "Trail: 0, Epoch: 161, Loss: 0.3304\n",
      "Trail: 0, Epoch: 162, Loss: 0.3236\n",
      "Trail: 0, Epoch: 163, Loss: 0.3184\n",
      "Trail: 0, Epoch: 164, Loss: 0.3244\n",
      "Trail: 0, Epoch: 165, Loss: 0.3240\n",
      "Trail: 0, Epoch: 166, Loss: 0.3175\n",
      "Trail: 0, Epoch: 167, Loss: 0.3185\n",
      "Trail: 0, Epoch: 168, Loss: 0.3249\n",
      "Trail: 0, Epoch: 169, Loss: 0.3195\n",
      "Trail: 0, Epoch: 170, Loss: 0.3324\n",
      "Trail: 0, Epoch: 171, Loss: 0.3315\n",
      "Trail: 0, Epoch: 172, Loss: 0.3290\n",
      "Trail: 0, Epoch: 173, Loss: 0.3170\n",
      "Trail: 0, Epoch: 174, Loss: 0.3163\n",
      "Trail: 0, Epoch: 175, Loss: 0.3188\n",
      "Trail: 0, Epoch: 176, Loss: 0.3218\n",
      "Trail: 0, Epoch: 177, Loss: 0.3140\n",
      "Trail: 0, Epoch: 178, Loss: 0.3211\n",
      "Trail: 0, Epoch: 179, Loss: 0.3218\n",
      "Trail: 0, Epoch: 180, Loss: 0.3212\n",
      "Trail: 0, Epoch: 181, Loss: 0.3254\n",
      "Trail: 0, Epoch: 182, Loss: 0.3149\n",
      "Trail: 0, Epoch: 183, Loss: 0.3171\n",
      "Trail: 0, Epoch: 184, Loss: 0.3230\n",
      "Trail: 0, Epoch: 185, Loss: 0.3183\n",
      "Trail: 0, Epoch: 186, Loss: 0.3369\n",
      "Trail: 0, Epoch: 187, Loss: 0.3229\n",
      "Trail: 0, Epoch: 188, Loss: 0.3284\n",
      "Trail: 0, Epoch: 189, Loss: 0.3216\n",
      "Trail: 0, Epoch: 190, Loss: 0.3258\n",
      "Trail: 0, Epoch: 191, Loss: 0.3168\n",
      "Trail: 0, Epoch: 192, Loss: 0.3235\n",
      "Trail: 0, Epoch: 193, Loss: 0.3226\n",
      "Trail: 0, Epoch: 194, Loss: 0.3203\n",
      "Trail: 0, Epoch: 195, Loss: 0.3172\n",
      "Trail: 0, Epoch: 196, Loss: 0.3158\n",
      "Trail: 0, Epoch: 197, Loss: 0.3132\n",
      "Trail: 0, Epoch: 198, Loss: 0.3174\n",
      "Trail: 0, Epoch: 199, Loss: 0.3148\n",
      "Trail: 0, Epoch: 200, Loss: 0.3183\n",
      "[[756 130]\n",
      " [ 23  86]]\n",
      "Fscore: 0.5292307692307693 Recall: 0.7889908256880734 Precision: 0.39814814814814814 Test: 0.8452261306532663\n",
      "========end this trail==========\n",
      "========begin trail 1===========\n",
      "Trail: 1, Epoch: 00, Loss: 0.6642\n",
      "[[541 345]\n",
      " [ 12  97]]\n",
      "Fscore: 0.35208711433756806 Recall: 0.8899082568807339 Precision: 0.21945701357466063 Test: 0.6030150753768844\n",
      "Trail: 1, Epoch: 01, Loss: 0.5226\n",
      "Trail: 1, Epoch: 02, Loss: 0.5057\n",
      "Trail: 1, Epoch: 03, Loss: 0.4754\n",
      "Trail: 1, Epoch: 04, Loss: 0.4641\n",
      "Trail: 1, Epoch: 05, Loss: 0.4454\n",
      "Trail: 1, Epoch: 06, Loss: 0.4381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trail: 1, Epoch: 07, Loss: 0.4287\n",
      "Trail: 1, Epoch: 08, Loss: 0.4207\n",
      "Trail: 1, Epoch: 09, Loss: 0.4234\n",
      "Trail: 1, Epoch: 10, Loss: 0.4178\n",
      "Trail: 1, Epoch: 11, Loss: 0.4036\n",
      "Trail: 1, Epoch: 12, Loss: 0.4079\n",
      "Trail: 1, Epoch: 13, Loss: 0.4080\n",
      "Trail: 1, Epoch: 14, Loss: 0.3971\n",
      "Trail: 1, Epoch: 15, Loss: 0.3956\n",
      "Trail: 1, Epoch: 16, Loss: 0.3931\n",
      "Trail: 1, Epoch: 17, Loss: 0.3900\n",
      "Trail: 1, Epoch: 18, Loss: 0.3856\n",
      "Trail: 1, Epoch: 19, Loss: 0.3834\n",
      "Trail: 1, Epoch: 20, Loss: 0.3965\n",
      "Trail: 1, Epoch: 21, Loss: 0.3879\n",
      "Trail: 1, Epoch: 22, Loss: 0.3826\n",
      "Trail: 1, Epoch: 23, Loss: 0.4011\n",
      "Trail: 1, Epoch: 24, Loss: 0.3841\n",
      "Trail: 1, Epoch: 25, Loss: 0.3756\n",
      "Trail: 1, Epoch: 26, Loss: 0.3784\n",
      "Trail: 1, Epoch: 27, Loss: 0.3709\n",
      "Trail: 1, Epoch: 28, Loss: 0.3863\n",
      "Trail: 1, Epoch: 29, Loss: 0.3773\n",
      "Trail: 1, Epoch: 30, Loss: 0.3693\n",
      "Trail: 1, Epoch: 31, Loss: 0.3669\n",
      "Trail: 1, Epoch: 32, Loss: 0.3632\n",
      "Trail: 1, Epoch: 33, Loss: 0.3696\n",
      "Trail: 1, Epoch: 34, Loss: 0.3679\n",
      "Trail: 1, Epoch: 35, Loss: 0.3647\n",
      "Trail: 1, Epoch: 36, Loss: 0.3664\n",
      "Trail: 1, Epoch: 37, Loss: 0.3636\n",
      "Trail: 1, Epoch: 38, Loss: 0.3641\n",
      "Trail: 1, Epoch: 39, Loss: 0.3614\n",
      "Trail: 1, Epoch: 40, Loss: 0.3581\n",
      "Trail: 1, Epoch: 41, Loss: 0.3594\n",
      "Trail: 1, Epoch: 42, Loss: 0.3585\n",
      "Trail: 1, Epoch: 43, Loss: 0.3555\n",
      "Trail: 1, Epoch: 44, Loss: 0.3590\n",
      "Trail: 1, Epoch: 45, Loss: 0.3588\n",
      "Trail: 1, Epoch: 46, Loss: 0.3553\n",
      "Trail: 1, Epoch: 47, Loss: 0.3562\n",
      "Trail: 1, Epoch: 48, Loss: 0.3659\n",
      "Trail: 1, Epoch: 49, Loss: 0.3559\n",
      "Trail: 1, Epoch: 50, Loss: 0.3524\n",
      "[[761 125]\n",
      " [ 19  90]]\n",
      "Fscore: 0.5555555555555556 Recall: 0.8256880733944955 Precision: 0.4186046511627907 Test: 0.8532663316582915\n",
      "Trail: 1, Epoch: 51, Loss: 0.3500\n",
      "Trail: 1, Epoch: 52, Loss: 0.3517\n",
      "Trail: 1, Epoch: 53, Loss: 0.3533\n",
      "Trail: 1, Epoch: 54, Loss: 0.3453\n",
      "Trail: 1, Epoch: 55, Loss: 0.3499\n",
      "Trail: 1, Epoch: 56, Loss: 0.3490\n",
      "Trail: 1, Epoch: 57, Loss: 0.3492\n",
      "Trail: 1, Epoch: 58, Loss: 0.3460\n",
      "Trail: 1, Epoch: 59, Loss: 0.3507\n",
      "Trail: 1, Epoch: 60, Loss: 0.3512\n",
      "Trail: 1, Epoch: 61, Loss: 0.3497\n",
      "Trail: 1, Epoch: 62, Loss: 0.3546\n",
      "Trail: 1, Epoch: 63, Loss: 0.3475\n",
      "Trail: 1, Epoch: 64, Loss: 0.3482\n",
      "Trail: 1, Epoch: 65, Loss: 0.3394\n",
      "Trail: 1, Epoch: 66, Loss: 0.3443\n",
      "Trail: 1, Epoch: 67, Loss: 0.3565\n",
      "Trail: 1, Epoch: 68, Loss: 0.3375\n",
      "Trail: 1, Epoch: 69, Loss: 0.3466\n",
      "Trail: 1, Epoch: 70, Loss: 0.3358\n",
      "Trail: 1, Epoch: 71, Loss: 0.3460\n",
      "Trail: 1, Epoch: 72, Loss: 0.3421\n",
      "Trail: 1, Epoch: 73, Loss: 0.3400\n",
      "Trail: 1, Epoch: 74, Loss: 0.3433\n",
      "Trail: 1, Epoch: 75, Loss: 0.3441\n",
      "Trail: 1, Epoch: 76, Loss: 0.3442\n",
      "Trail: 1, Epoch: 77, Loss: 0.3418\n",
      "Trail: 1, Epoch: 78, Loss: 0.3426\n",
      "Trail: 1, Epoch: 79, Loss: 0.3397\n",
      "Trail: 1, Epoch: 80, Loss: 0.3483\n",
      "Trail: 1, Epoch: 81, Loss: 0.3395\n",
      "Trail: 1, Epoch: 82, Loss: 0.3419\n",
      "Trail: 1, Epoch: 83, Loss: 0.3392\n",
      "Trail: 1, Epoch: 84, Loss: 0.3407\n",
      "Trail: 1, Epoch: 85, Loss: 0.3448\n",
      "Trail: 1, Epoch: 86, Loss: 0.3418\n",
      "Trail: 1, Epoch: 87, Loss: 0.3373\n",
      "Trail: 1, Epoch: 88, Loss: 0.3389\n",
      "Trail: 1, Epoch: 89, Loss: 0.3308\n",
      "Trail: 1, Epoch: 90, Loss: 0.3342\n",
      "Trail: 1, Epoch: 91, Loss: 0.3415\n",
      "Trail: 1, Epoch: 92, Loss: 0.3404\n",
      "Trail: 1, Epoch: 93, Loss: 0.3305\n",
      "Trail: 1, Epoch: 94, Loss: 0.3368\n",
      "Trail: 1, Epoch: 95, Loss: 0.3375\n",
      "Trail: 1, Epoch: 96, Loss: 0.3428\n",
      "Trail: 1, Epoch: 97, Loss: 0.3347\n",
      "Trail: 1, Epoch: 98, Loss: 0.3420\n",
      "Trail: 1, Epoch: 99, Loss: 0.3357\n",
      "Trail: 1, Epoch: 100, Loss: 0.3385\n",
      "[[737 149]\n",
      " [ 15  94]]\n",
      "Fscore: 0.5340909090909092 Recall: 0.8623853211009175 Precision: 0.3868312757201646 Test: 0.8341708542713567\n",
      "Trail: 1, Epoch: 101, Loss: 0.3379\n",
      "Trail: 1, Epoch: 102, Loss: 0.3362\n",
      "Trail: 1, Epoch: 103, Loss: 0.3399\n",
      "Trail: 1, Epoch: 104, Loss: 0.3382\n",
      "Trail: 1, Epoch: 105, Loss: 0.3364\n",
      "Trail: 1, Epoch: 106, Loss: 0.3412\n",
      "Trail: 1, Epoch: 107, Loss: 0.3345\n",
      "Trail: 1, Epoch: 108, Loss: 0.3387\n",
      "Trail: 1, Epoch: 109, Loss: 0.3338\n",
      "Trail: 1, Epoch: 110, Loss: 0.3349\n",
      "Trail: 1, Epoch: 111, Loss: 0.3307\n",
      "Trail: 1, Epoch: 112, Loss: 0.3383\n",
      "Trail: 1, Epoch: 113, Loss: 0.3381\n",
      "Trail: 1, Epoch: 114, Loss: 0.3357\n",
      "Trail: 1, Epoch: 115, Loss: 0.3502\n",
      "Trail: 1, Epoch: 116, Loss: 0.3347\n",
      "Trail: 1, Epoch: 117, Loss: 0.3327\n",
      "Trail: 1, Epoch: 118, Loss: 0.3346\n",
      "Trail: 1, Epoch: 119, Loss: 0.3272\n",
      "Trail: 1, Epoch: 120, Loss: 0.3335\n",
      "Trail: 1, Epoch: 121, Loss: 0.3366\n",
      "Trail: 1, Epoch: 122, Loss: 0.3417\n",
      "Trail: 1, Epoch: 123, Loss: 0.3303\n",
      "Trail: 1, Epoch: 124, Loss: 0.3342\n",
      "Trail: 1, Epoch: 125, Loss: 0.3310\n",
      "Trail: 1, Epoch: 126, Loss: 0.3331\n",
      "Trail: 1, Epoch: 127, Loss: 0.3393\n",
      "Trail: 1, Epoch: 128, Loss: 0.3307\n",
      "Trail: 1, Epoch: 129, Loss: 0.3812\n",
      "Trail: 1, Epoch: 130, Loss: 0.3313\n",
      "Trail: 1, Epoch: 131, Loss: 0.3295\n",
      "Trail: 1, Epoch: 132, Loss: 0.3335\n",
      "Trail: 1, Epoch: 133, Loss: 0.3438\n",
      "Trail: 1, Epoch: 134, Loss: 0.3428\n",
      "Trail: 1, Epoch: 135, Loss: 0.3348\n",
      "Trail: 1, Epoch: 136, Loss: 0.3256\n",
      "Trail: 1, Epoch: 137, Loss: 0.3296\n",
      "Trail: 1, Epoch: 138, Loss: 0.3286\n",
      "Trail: 1, Epoch: 139, Loss: 0.3276\n",
      "Trail: 1, Epoch: 140, Loss: 0.3251\n",
      "Trail: 1, Epoch: 141, Loss: 0.3269\n",
      "Trail: 1, Epoch: 142, Loss: 0.3324\n",
      "Trail: 1, Epoch: 143, Loss: 0.3354\n",
      "Trail: 1, Epoch: 144, Loss: 0.3290\n",
      "Trail: 1, Epoch: 145, Loss: 0.3298\n",
      "Trail: 1, Epoch: 146, Loss: 0.3255\n",
      "Trail: 1, Epoch: 147, Loss: 0.3198\n",
      "Trail: 1, Epoch: 148, Loss: 0.3341\n",
      "Trail: 1, Epoch: 149, Loss: 0.3291\n",
      "Trail: 1, Epoch: 150, Loss: 0.3307\n",
      "[[776 110]\n",
      " [ 19  90]]\n",
      "Fscore: 0.5825242718446603 Recall: 0.8256880733944955 Precision: 0.45 Test: 0.8693467336683417\n",
      "Trail: 1, Epoch: 151, Loss: 0.3303\n",
      "Trail: 1, Epoch: 152, Loss: 0.3266\n",
      "Trail: 1, Epoch: 153, Loss: 0.3281\n",
      "Trail: 1, Epoch: 154, Loss: 0.3230\n",
      "Trail: 1, Epoch: 155, Loss: 0.3252\n",
      "Trail: 1, Epoch: 156, Loss: 0.3219\n",
      "Trail: 1, Epoch: 157, Loss: 0.3297\n",
      "Trail: 1, Epoch: 158, Loss: 0.3288\n",
      "Trail: 1, Epoch: 159, Loss: 0.3272\n",
      "Trail: 1, Epoch: 160, Loss: 0.3264\n",
      "Trail: 1, Epoch: 161, Loss: 0.3279\n",
      "Trail: 1, Epoch: 162, Loss: 0.3249\n",
      "Trail: 1, Epoch: 163, Loss: 0.3234\n",
      "Trail: 1, Epoch: 164, Loss: 0.3205\n",
      "Trail: 1, Epoch: 165, Loss: 0.3420\n",
      "Trail: 1, Epoch: 166, Loss: 0.3249\n",
      "Trail: 1, Epoch: 167, Loss: 0.3240\n",
      "Trail: 1, Epoch: 168, Loss: 0.3230\n",
      "Trail: 1, Epoch: 169, Loss: 0.3231\n",
      "Trail: 1, Epoch: 170, Loss: 0.3269\n",
      "Trail: 1, Epoch: 171, Loss: 0.3162\n",
      "Trail: 1, Epoch: 172, Loss: 0.3229\n",
      "Trail: 1, Epoch: 173, Loss: 0.3272\n",
      "Trail: 1, Epoch: 174, Loss: 0.3221\n",
      "Trail: 1, Epoch: 175, Loss: 0.3193\n",
      "Trail: 1, Epoch: 176, Loss: 0.3238\n",
      "Trail: 1, Epoch: 177, Loss: 0.3251\n",
      "Trail: 1, Epoch: 178, Loss: 0.3247\n",
      "Trail: 1, Epoch: 179, Loss: 0.3229\n",
      "Trail: 1, Epoch: 180, Loss: 0.3246\n",
      "Trail: 1, Epoch: 181, Loss: 0.3199\n",
      "Trail: 1, Epoch: 182, Loss: 0.3226\n",
      "Trail: 1, Epoch: 183, Loss: 0.3204\n",
      "Trail: 1, Epoch: 184, Loss: 0.3228\n",
      "Trail: 1, Epoch: 185, Loss: 0.3205\n",
      "Trail: 1, Epoch: 186, Loss: 0.3219\n",
      "Trail: 1, Epoch: 187, Loss: 0.3237\n",
      "Trail: 1, Epoch: 188, Loss: 0.3214\n",
      "Trail: 1, Epoch: 189, Loss: 0.3240\n",
      "Trail: 1, Epoch: 190, Loss: 0.3247\n",
      "Trail: 1, Epoch: 191, Loss: 0.3285\n",
      "Trail: 1, Epoch: 192, Loss: 0.3198\n",
      "Trail: 1, Epoch: 193, Loss: 0.3158\n",
      "Trail: 1, Epoch: 194, Loss: 0.3242\n",
      "Trail: 1, Epoch: 195, Loss: 0.3208\n",
      "Trail: 1, Epoch: 196, Loss: 0.3182\n",
      "Trail: 1, Epoch: 197, Loss: 0.3248\n",
      "Trail: 1, Epoch: 198, Loss: 0.3130\n",
      "Trail: 1, Epoch: 199, Loss: 0.3176\n",
      "Trail: 1, Epoch: 200, Loss: 0.3208\n",
      "[[742 144]\n",
      " [ 14  95]]\n",
      "Fscore: 0.5459770114942528 Recall: 0.8715596330275229 Precision: 0.39748953974895396 Test: 0.8402010050251256\n",
      "========end this trail==========\n",
      "========begin trail 2===========\n",
      "Trail: 2, Epoch: 00, Loss: 0.7514\n",
      "[[545 340]\n",
      " [ 11  98]]\n",
      "Fscore: 0.35831809872029247 Recall: 0.8990825688073395 Precision: 0.2237442922374429 Test: 0.5945674044265593\n",
      "Trail: 2, Epoch: 01, Loss: 0.5575\n",
      "Trail: 2, Epoch: 02, Loss: 0.5082\n",
      "Trail: 2, Epoch: 03, Loss: 0.4854\n",
      "Trail: 2, Epoch: 04, Loss: 0.4633\n",
      "Trail: 2, Epoch: 05, Loss: 0.4473\n",
      "Trail: 2, Epoch: 06, Loss: 0.4594\n",
      "Trail: 2, Epoch: 07, Loss: 0.4315\n",
      "Trail: 2, Epoch: 08, Loss: 0.4260\n",
      "Trail: 2, Epoch: 09, Loss: 0.4136\n",
      "Trail: 2, Epoch: 10, Loss: 0.4135\n",
      "Trail: 2, Epoch: 11, Loss: 0.4036\n",
      "Trail: 2, Epoch: 12, Loss: 0.3959\n",
      "Trail: 2, Epoch: 13, Loss: 0.3949\n",
      "Trail: 2, Epoch: 14, Loss: 0.4000\n",
      "Trail: 2, Epoch: 15, Loss: 0.3843\n",
      "Trail: 2, Epoch: 16, Loss: 0.3864\n",
      "Trail: 2, Epoch: 17, Loss: 0.3805\n",
      "Trail: 2, Epoch: 18, Loss: 0.3971\n",
      "Trail: 2, Epoch: 19, Loss: 0.3872\n",
      "Trail: 2, Epoch: 20, Loss: 0.3802\n",
      "Trail: 2, Epoch: 21, Loss: 0.3690\n",
      "Trail: 2, Epoch: 22, Loss: 0.3752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trail: 2, Epoch: 23, Loss: 0.3738\n",
      "Trail: 2, Epoch: 24, Loss: 0.3703\n",
      "Trail: 2, Epoch: 25, Loss: 0.3668\n",
      "Trail: 2, Epoch: 26, Loss: 0.3710\n",
      "Trail: 2, Epoch: 27, Loss: 0.3674\n",
      "Trail: 2, Epoch: 28, Loss: 0.3595\n",
      "Trail: 2, Epoch: 29, Loss: 0.3615\n",
      "Trail: 2, Epoch: 30, Loss: 0.3575\n",
      "Trail: 2, Epoch: 31, Loss: 0.3573\n",
      "Trail: 2, Epoch: 32, Loss: 0.3582\n",
      "Trail: 2, Epoch: 33, Loss: 0.3580\n",
      "Trail: 2, Epoch: 34, Loss: 0.3514\n",
      "Trail: 2, Epoch: 35, Loss: 0.3532\n",
      "Trail: 2, Epoch: 36, Loss: 0.3556\n",
      "Trail: 2, Epoch: 37, Loss: 0.3517\n",
      "Trail: 2, Epoch: 38, Loss: 0.3529\n",
      "Trail: 2, Epoch: 39, Loss: 0.3524\n",
      "Trail: 2, Epoch: 40, Loss: 0.3496\n",
      "Trail: 2, Epoch: 41, Loss: 0.3531\n",
      "Trail: 2, Epoch: 42, Loss: 0.3622\n",
      "Trail: 2, Epoch: 43, Loss: 0.3528\n",
      "Trail: 2, Epoch: 44, Loss: 0.3426\n",
      "Trail: 2, Epoch: 45, Loss: 0.3499\n",
      "Trail: 2, Epoch: 46, Loss: 0.3453\n",
      "Trail: 2, Epoch: 47, Loss: 0.3404\n",
      "Trail: 2, Epoch: 48, Loss: 0.3494\n",
      "Trail: 2, Epoch: 49, Loss: 0.3472\n",
      "Trail: 2, Epoch: 50, Loss: 0.3445\n",
      "[[750 135]\n",
      " [ 21  88]]\n",
      "Fscore: 0.5301204819277108 Recall: 0.8073394495412844 Precision: 0.39461883408071746 Test: 0.8430583501006036\n",
      "Trail: 2, Epoch: 51, Loss: 0.3429\n",
      "Trail: 2, Epoch: 52, Loss: 0.3411\n",
      "Trail: 2, Epoch: 53, Loss: 0.3396\n",
      "Trail: 2, Epoch: 54, Loss: 0.3409\n",
      "Trail: 2, Epoch: 55, Loss: 0.3424\n",
      "Trail: 2, Epoch: 56, Loss: 0.3384\n",
      "Trail: 2, Epoch: 57, Loss: 0.3440\n",
      "Trail: 2, Epoch: 58, Loss: 0.3358\n",
      "Trail: 2, Epoch: 59, Loss: 0.3676\n",
      "Trail: 2, Epoch: 60, Loss: 0.3402\n",
      "Trail: 2, Epoch: 61, Loss: 0.3380\n",
      "Trail: 2, Epoch: 62, Loss: 0.3340\n",
      "Trail: 2, Epoch: 63, Loss: 0.3400\n",
      "Trail: 2, Epoch: 64, Loss: 0.3459\n",
      "Trail: 2, Epoch: 65, Loss: 0.3446\n",
      "Trail: 2, Epoch: 66, Loss: 0.3387\n",
      "Trail: 2, Epoch: 67, Loss: 0.3352\n",
      "Trail: 2, Epoch: 68, Loss: 0.3307\n",
      "Trail: 2, Epoch: 69, Loss: 0.3365\n",
      "Trail: 2, Epoch: 70, Loss: 0.3369\n",
      "Trail: 2, Epoch: 71, Loss: 0.3358\n",
      "Trail: 2, Epoch: 72, Loss: 0.3296\n",
      "Trail: 2, Epoch: 73, Loss: 0.3290\n",
      "Trail: 2, Epoch: 74, Loss: 0.3344\n",
      "Trail: 2, Epoch: 75, Loss: 0.3334\n",
      "Trail: 2, Epoch: 76, Loss: 0.3325\n",
      "Trail: 2, Epoch: 77, Loss: 0.3355\n",
      "Trail: 2, Epoch: 78, Loss: 0.3320\n",
      "Trail: 2, Epoch: 79, Loss: 0.3328\n",
      "Trail: 2, Epoch: 80, Loss: 0.3292\n",
      "Trail: 2, Epoch: 81, Loss: 0.3259\n",
      "Trail: 2, Epoch: 82, Loss: 0.3362\n",
      "Trail: 2, Epoch: 83, Loss: 0.3359\n",
      "Trail: 2, Epoch: 84, Loss: 0.3262\n",
      "Trail: 2, Epoch: 85, Loss: 0.3266\n",
      "Trail: 2, Epoch: 86, Loss: 0.3306\n",
      "Trail: 2, Epoch: 87, Loss: 0.3289\n",
      "Trail: 2, Epoch: 88, Loss: 0.3258\n",
      "Trail: 2, Epoch: 89, Loss: 0.3282\n",
      "Trail: 2, Epoch: 90, Loss: 0.3247\n",
      "Trail: 2, Epoch: 91, Loss: 0.3318\n",
      "Trail: 2, Epoch: 92, Loss: 0.3374\n",
      "Trail: 2, Epoch: 93, Loss: 0.3304\n",
      "Trail: 2, Epoch: 94, Loss: 0.3236\n",
      "Trail: 2, Epoch: 95, Loss: 0.3287\n",
      "Trail: 2, Epoch: 96, Loss: 0.3288\n",
      "Trail: 2, Epoch: 97, Loss: 0.3226\n",
      "Trail: 2, Epoch: 98, Loss: 0.3251\n",
      "Trail: 2, Epoch: 99, Loss: 0.3291\n",
      "Trail: 2, Epoch: 100, Loss: 0.3252\n",
      "[[814  71]\n",
      " [ 45  64]]\n",
      "Fscore: 0.5245901639344263 Recall: 0.5871559633027523 Precision: 0.4740740740740741 Test: 0.8822937625754527\n",
      "Trail: 2, Epoch: 101, Loss: 0.3373\n",
      "Trail: 2, Epoch: 102, Loss: 0.3344\n",
      "Trail: 2, Epoch: 103, Loss: 0.3196\n",
      "Trail: 2, Epoch: 104, Loss: 0.3214\n",
      "Trail: 2, Epoch: 105, Loss: 0.3228\n",
      "Trail: 2, Epoch: 106, Loss: 0.3291\n",
      "Trail: 2, Epoch: 107, Loss: 0.3220\n",
      "Trail: 2, Epoch: 108, Loss: 0.3269\n",
      "Trail: 2, Epoch: 109, Loss: 0.3215\n",
      "Trail: 2, Epoch: 110, Loss: 0.3138\n",
      "Trail: 2, Epoch: 111, Loss: 0.3211\n",
      "Trail: 2, Epoch: 112, Loss: 0.3184\n",
      "Trail: 2, Epoch: 113, Loss: 0.3201\n",
      "Trail: 2, Epoch: 114, Loss: 0.3233\n",
      "Trail: 2, Epoch: 115, Loss: 0.3184\n",
      "Trail: 2, Epoch: 116, Loss: 0.3159\n",
      "Trail: 2, Epoch: 117, Loss: 0.3214\n",
      "Trail: 2, Epoch: 118, Loss: 0.3219\n",
      "Trail: 2, Epoch: 119, Loss: 0.3272\n",
      "Trail: 2, Epoch: 120, Loss: 0.3218\n",
      "Trail: 2, Epoch: 121, Loss: 0.3220\n",
      "Trail: 2, Epoch: 122, Loss: 0.3174\n",
      "Trail: 2, Epoch: 123, Loss: 0.3143\n",
      "Trail: 2, Epoch: 124, Loss: 0.3212\n",
      "Trail: 2, Epoch: 125, Loss: 0.3221\n",
      "Trail: 2, Epoch: 126, Loss: 0.3239\n",
      "Trail: 2, Epoch: 127, Loss: 0.3153\n",
      "Trail: 2, Epoch: 128, Loss: 0.3148\n",
      "Trail: 2, Epoch: 129, Loss: 0.3193\n",
      "Trail: 2, Epoch: 130, Loss: 0.3134\n",
      "Trail: 2, Epoch: 131, Loss: 0.3214\n",
      "Trail: 2, Epoch: 132, Loss: 0.3176\n",
      "Trail: 2, Epoch: 133, Loss: 0.3160\n",
      "Trail: 2, Epoch: 134, Loss: 0.3168\n",
      "Trail: 2, Epoch: 135, Loss: 0.3187\n",
      "Trail: 2, Epoch: 136, Loss: 0.3189\n",
      "Trail: 2, Epoch: 137, Loss: 0.3140\n",
      "Trail: 2, Epoch: 138, Loss: 0.3160\n",
      "Trail: 2, Epoch: 139, Loss: 0.3180\n",
      "Trail: 2, Epoch: 140, Loss: 0.3130\n",
      "Trail: 2, Epoch: 141, Loss: 0.3101\n",
      "Trail: 2, Epoch: 142, Loss: 0.3188\n",
      "Trail: 2, Epoch: 143, Loss: 0.3124\n",
      "Trail: 2, Epoch: 144, Loss: 0.3202\n",
      "Trail: 2, Epoch: 145, Loss: 0.3156\n",
      "Trail: 2, Epoch: 146, Loss: 0.3185\n",
      "Trail: 2, Epoch: 147, Loss: 0.3214\n",
      "Trail: 2, Epoch: 148, Loss: 0.3158\n",
      "Trail: 2, Epoch: 149, Loss: 0.3135\n",
      "Trail: 2, Epoch: 150, Loss: 0.3182\n",
      "[[774 111]\n",
      " [ 28  81]]\n",
      "Fscore: 0.5382059800664452 Recall: 0.7431192660550459 Precision: 0.421875 Test: 0.8591549295774648\n",
      "Trail: 2, Epoch: 151, Loss: 0.3112\n",
      "Trail: 2, Epoch: 152, Loss: 0.3122\n",
      "Trail: 2, Epoch: 153, Loss: 0.3164\n",
      "Trail: 2, Epoch: 154, Loss: 0.3094\n",
      "Trail: 2, Epoch: 155, Loss: 0.3135\n",
      "Trail: 2, Epoch: 156, Loss: 0.3184\n",
      "Trail: 2, Epoch: 157, Loss: 0.3214\n",
      "Trail: 2, Epoch: 158, Loss: 0.3110\n",
      "Trail: 2, Epoch: 159, Loss: 0.3164\n",
      "Trail: 2, Epoch: 160, Loss: 0.3232\n",
      "Trail: 2, Epoch: 161, Loss: 0.3118\n",
      "Trail: 2, Epoch: 162, Loss: 0.3110\n",
      "Trail: 2, Epoch: 163, Loss: 0.3162\n",
      "Trail: 2, Epoch: 164, Loss: 0.3172\n",
      "Trail: 2, Epoch: 165, Loss: 0.3061\n",
      "Trail: 2, Epoch: 166, Loss: 0.3128\n",
      "Trail: 2, Epoch: 167, Loss: 0.3182\n",
      "Trail: 2, Epoch: 168, Loss: 0.3075\n",
      "Trail: 2, Epoch: 169, Loss: 0.3096\n",
      "Trail: 2, Epoch: 170, Loss: 0.3092\n",
      "Trail: 2, Epoch: 171, Loss: 0.3154\n",
      "Trail: 2, Epoch: 172, Loss: 0.3092\n",
      "Trail: 2, Epoch: 173, Loss: 0.3109\n",
      "Trail: 2, Epoch: 174, Loss: 0.3191\n",
      "Trail: 2, Epoch: 175, Loss: 0.3086\n",
      "Trail: 2, Epoch: 176, Loss: 0.3146\n",
      "Trail: 2, Epoch: 177, Loss: 0.3110\n",
      "Trail: 2, Epoch: 178, Loss: 0.3065\n",
      "Trail: 2, Epoch: 179, Loss: 0.3094\n",
      "Trail: 2, Epoch: 180, Loss: 0.3101\n",
      "Trail: 2, Epoch: 181, Loss: 0.3155\n",
      "Trail: 2, Epoch: 182, Loss: 0.3085\n",
      "Trail: 2, Epoch: 183, Loss: 0.3052\n",
      "Trail: 2, Epoch: 184, Loss: 0.3079\n",
      "Trail: 2, Epoch: 185, Loss: 0.3115\n",
      "Trail: 2, Epoch: 186, Loss: 0.3128\n",
      "Trail: 2, Epoch: 187, Loss: 0.3040\n",
      "Trail: 2, Epoch: 188, Loss: 0.3120\n",
      "Trail: 2, Epoch: 189, Loss: 0.3122\n",
      "Trail: 2, Epoch: 190, Loss: 0.3148\n",
      "Trail: 2, Epoch: 191, Loss: 0.3107\n",
      "Trail: 2, Epoch: 192, Loss: 0.3101\n",
      "Trail: 2, Epoch: 193, Loss: 0.3088\n",
      "Trail: 2, Epoch: 194, Loss: 0.3105\n",
      "Trail: 2, Epoch: 195, Loss: 0.3092\n",
      "Trail: 2, Epoch: 196, Loss: 0.3112\n",
      "Trail: 2, Epoch: 197, Loss: 0.3080\n",
      "Trail: 2, Epoch: 198, Loss: 0.3138\n",
      "Trail: 2, Epoch: 199, Loss: 0.3070\n",
      "Trail: 2, Epoch: 200, Loss: 0.3050\n",
      "[[683 202]\n",
      " [ 15  94]]\n",
      "Fscore: 0.46419753086419746 Recall: 0.8623853211009175 Precision: 0.31756756756756754 Test: 0.7816901408450704\n",
      "========end this trail==========\n",
      "========begin trail 3===========\n",
      "Trail: 3, Epoch: 00, Loss: 0.7058\n",
      "[[604 281]\n",
      " [ 22  87]]\n",
      "Fscore: 0.36477987421383645 Recall: 0.7981651376146789 Precision: 0.23641304347826086 Test: 0.6589537223340041\n",
      "Trail: 3, Epoch: 01, Loss: 0.5253\n",
      "Trail: 3, Epoch: 02, Loss: 0.4877\n",
      "Trail: 3, Epoch: 03, Loss: 0.4603\n",
      "Trail: 3, Epoch: 04, Loss: 0.4434\n",
      "Trail: 3, Epoch: 05, Loss: 0.4319\n",
      "Trail: 3, Epoch: 06, Loss: 0.4195\n",
      "Trail: 3, Epoch: 07, Loss: 0.4099\n",
      "Trail: 3, Epoch: 08, Loss: 0.4356\n",
      "Trail: 3, Epoch: 09, Loss: 0.4051\n",
      "Trail: 3, Epoch: 10, Loss: 0.3931\n",
      "Trail: 3, Epoch: 11, Loss: 0.3869\n",
      "Trail: 3, Epoch: 12, Loss: 0.3870\n",
      "Trail: 3, Epoch: 13, Loss: 0.3758\n",
      "Trail: 3, Epoch: 14, Loss: 0.3774\n",
      "Trail: 3, Epoch: 15, Loss: 0.3710\n",
      "Trail: 3, Epoch: 16, Loss: 0.3709\n",
      "Trail: 3, Epoch: 17, Loss: 0.3646\n",
      "Trail: 3, Epoch: 18, Loss: 0.3627\n",
      "Trail: 3, Epoch: 19, Loss: 0.3645\n",
      "Trail: 3, Epoch: 20, Loss: 0.3610\n",
      "Trail: 3, Epoch: 21, Loss: 0.3613\n",
      "Trail: 3, Epoch: 22, Loss: 0.3512\n",
      "Trail: 3, Epoch: 23, Loss: 0.3568\n",
      "Trail: 3, Epoch: 24, Loss: 0.3534\n",
      "Trail: 3, Epoch: 25, Loss: 0.3525\n",
      "Trail: 3, Epoch: 26, Loss: 0.3490\n",
      "Trail: 3, Epoch: 27, Loss: 0.3464\n",
      "Trail: 3, Epoch: 28, Loss: 0.3510\n",
      "Trail: 3, Epoch: 29, Loss: 0.3457\n",
      "Trail: 3, Epoch: 30, Loss: 0.3525\n",
      "Trail: 3, Epoch: 31, Loss: 0.3467\n",
      "Trail: 3, Epoch: 32, Loss: 0.3458\n",
      "Trail: 3, Epoch: 33, Loss: 0.3462\n",
      "Trail: 3, Epoch: 34, Loss: 0.3465\n",
      "Trail: 3, Epoch: 35, Loss: 0.3450\n",
      "Trail: 3, Epoch: 36, Loss: 0.3503\n",
      "Trail: 3, Epoch: 37, Loss: 0.3425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trail: 3, Epoch: 38, Loss: 0.3397\n",
      "Trail: 3, Epoch: 39, Loss: 0.3381\n",
      "Trail: 3, Epoch: 40, Loss: 0.3389\n",
      "Trail: 3, Epoch: 41, Loss: 0.3329\n",
      "Trail: 3, Epoch: 42, Loss: 0.3379\n",
      "Trail: 3, Epoch: 43, Loss: 0.3302\n",
      "Trail: 3, Epoch: 44, Loss: 0.3343\n",
      "Trail: 3, Epoch: 45, Loss: 0.3266\n",
      "Trail: 3, Epoch: 46, Loss: 0.3286\n",
      "Trail: 3, Epoch: 47, Loss: 0.3312\n",
      "Trail: 3, Epoch: 48, Loss: 0.3299\n",
      "Trail: 3, Epoch: 49, Loss: 0.3279\n",
      "Trail: 3, Epoch: 50, Loss: 0.3282\n",
      "[[668 217]\n",
      " [ 26  83]]\n",
      "Fscore: 0.4058679706601467 Recall: 0.7614678899082569 Precision: 0.27666666666666667 Test: 0.755533199195171\n",
      "Trail: 3, Epoch: 51, Loss: 0.3286\n",
      "Trail: 3, Epoch: 52, Loss: 0.3273\n",
      "Trail: 3, Epoch: 53, Loss: 0.3248\n",
      "Trail: 3, Epoch: 54, Loss: 0.3342\n",
      "Trail: 3, Epoch: 55, Loss: 0.3335\n",
      "Trail: 3, Epoch: 56, Loss: 0.3298\n",
      "Trail: 3, Epoch: 57, Loss: 0.3299\n",
      "Trail: 3, Epoch: 58, Loss: 0.3292\n",
      "Trail: 3, Epoch: 59, Loss: 0.3240\n",
      "Trail: 3, Epoch: 60, Loss: 0.3227\n",
      "Trail: 3, Epoch: 61, Loss: 0.3252\n",
      "Trail: 3, Epoch: 62, Loss: 0.3322\n",
      "Trail: 3, Epoch: 63, Loss: 0.3176\n",
      "Trail: 3, Epoch: 64, Loss: 0.3276\n",
      "Trail: 3, Epoch: 65, Loss: 0.3246\n",
      "Trail: 3, Epoch: 66, Loss: 0.3199\n",
      "Trail: 3, Epoch: 67, Loss: 0.3255\n",
      "Trail: 3, Epoch: 68, Loss: 0.3197\n",
      "Trail: 3, Epoch: 69, Loss: 0.3187\n",
      "Trail: 3, Epoch: 70, Loss: 0.3234\n",
      "Trail: 3, Epoch: 71, Loss: 0.3162\n",
      "Trail: 3, Epoch: 72, Loss: 0.3182\n",
      "Trail: 3, Epoch: 73, Loss: 0.3140\n",
      "Trail: 3, Epoch: 74, Loss: 0.3188\n",
      "Trail: 3, Epoch: 75, Loss: 0.3243\n",
      "Trail: 3, Epoch: 76, Loss: 0.3246\n",
      "Trail: 3, Epoch: 77, Loss: 0.3159\n",
      "Trail: 3, Epoch: 78, Loss: 0.3165\n",
      "Trail: 3, Epoch: 79, Loss: 0.3229\n",
      "Trail: 3, Epoch: 80, Loss: 0.3180\n",
      "Trail: 3, Epoch: 81, Loss: 0.3161\n",
      "Trail: 3, Epoch: 82, Loss: 0.3271\n",
      "Trail: 3, Epoch: 83, Loss: 0.3134\n",
      "Trail: 3, Epoch: 84, Loss: 0.3142\n",
      "Trail: 3, Epoch: 85, Loss: 0.3135\n",
      "Trail: 3, Epoch: 86, Loss: 0.3129\n",
      "Trail: 3, Epoch: 87, Loss: 0.3148\n",
      "Trail: 3, Epoch: 88, Loss: 0.3159\n",
      "Trail: 3, Epoch: 89, Loss: 0.3134\n",
      "Trail: 3, Epoch: 90, Loss: 0.3126\n",
      "Trail: 3, Epoch: 91, Loss: 0.3185\n",
      "Trail: 3, Epoch: 92, Loss: 0.3087\n",
      "Trail: 3, Epoch: 93, Loss: 0.3113\n",
      "Trail: 3, Epoch: 94, Loss: 0.3284\n",
      "Trail: 3, Epoch: 95, Loss: 0.3273\n",
      "Trail: 3, Epoch: 96, Loss: 0.3119\n",
      "Trail: 3, Epoch: 97, Loss: 0.3157\n",
      "Trail: 3, Epoch: 98, Loss: 0.3088\n",
      "Trail: 3, Epoch: 99, Loss: 0.3144\n",
      "Trail: 3, Epoch: 100, Loss: 0.3138\n",
      "[[761 124]\n",
      " [ 29  80]]\n",
      "Fscore: 0.5111821086261982 Recall: 0.7339449541284404 Precision: 0.39215686274509803 Test: 0.8460764587525151\n",
      "Trail: 3, Epoch: 101, Loss: 0.3087\n",
      "Trail: 3, Epoch: 102, Loss: 0.3121\n",
      "Trail: 3, Epoch: 103, Loss: 0.3101\n",
      "Trail: 3, Epoch: 104, Loss: 0.3145\n",
      "Trail: 3, Epoch: 105, Loss: 0.3093\n",
      "Trail: 3, Epoch: 106, Loss: 0.3085\n",
      "Trail: 3, Epoch: 107, Loss: 0.3109\n",
      "Trail: 3, Epoch: 108, Loss: 0.3162\n",
      "Trail: 3, Epoch: 109, Loss: 0.3038\n",
      "Trail: 3, Epoch: 110, Loss: 0.3064\n",
      "Trail: 3, Epoch: 111, Loss: 0.3102\n",
      "Trail: 3, Epoch: 112, Loss: 0.3083\n",
      "Trail: 3, Epoch: 113, Loss: 0.3038\n",
      "Trail: 3, Epoch: 114, Loss: 0.3122\n",
      "Trail: 3, Epoch: 115, Loss: 0.3103\n",
      "Trail: 3, Epoch: 116, Loss: 0.3099\n",
      "Trail: 3, Epoch: 117, Loss: 0.3102\n",
      "Trail: 3, Epoch: 118, Loss: 0.3119\n",
      "Trail: 3, Epoch: 119, Loss: 0.3096\n",
      "Trail: 3, Epoch: 120, Loss: 0.3109\n",
      "Trail: 3, Epoch: 121, Loss: 0.3120\n",
      "Trail: 3, Epoch: 122, Loss: 0.3057\n",
      "Trail: 3, Epoch: 123, Loss: 0.3009\n",
      "Trail: 3, Epoch: 124, Loss: 0.3020\n",
      "Trail: 3, Epoch: 125, Loss: 0.3067\n",
      "Trail: 3, Epoch: 126, Loss: 0.3050\n",
      "Trail: 3, Epoch: 127, Loss: 0.3028\n",
      "Trail: 3, Epoch: 128, Loss: 0.3020\n",
      "Trail: 3, Epoch: 129, Loss: 0.3153\n",
      "Trail: 3, Epoch: 130, Loss: 0.3129\n",
      "Trail: 3, Epoch: 131, Loss: 0.3010\n",
      "Trail: 3, Epoch: 132, Loss: 0.3074\n",
      "Trail: 3, Epoch: 133, Loss: 0.2993\n",
      "Trail: 3, Epoch: 134, Loss: 0.3017\n",
      "Trail: 3, Epoch: 135, Loss: 0.3023\n",
      "Trail: 3, Epoch: 136, Loss: 0.3041\n",
      "Trail: 3, Epoch: 137, Loss: 0.3102\n",
      "Trail: 3, Epoch: 138, Loss: 0.3055\n",
      "Trail: 3, Epoch: 139, Loss: 0.3045\n",
      "Trail: 3, Epoch: 140, Loss: 0.3057\n",
      "Trail: 3, Epoch: 141, Loss: 0.3059\n",
      "Trail: 3, Epoch: 142, Loss: 0.3075\n",
      "Trail: 3, Epoch: 143, Loss: 0.3023\n",
      "Trail: 3, Epoch: 144, Loss: 0.2992\n",
      "Trail: 3, Epoch: 145, Loss: 0.3069\n",
      "Trail: 3, Epoch: 146, Loss: 0.3055\n",
      "Trail: 3, Epoch: 147, Loss: 0.3070\n",
      "Trail: 3, Epoch: 148, Loss: 0.3025\n",
      "Trail: 3, Epoch: 149, Loss: 0.3069\n",
      "Trail: 3, Epoch: 150, Loss: 0.2960\n",
      "[[772 113]\n",
      " [ 34  75]]\n",
      "Fscore: 0.5050505050505051 Recall: 0.6880733944954128 Precision: 0.39893617021276595 Test: 0.852112676056338\n",
      "Trail: 3, Epoch: 151, Loss: 0.3013\n",
      "Trail: 3, Epoch: 152, Loss: 0.2993\n",
      "Trail: 3, Epoch: 153, Loss: 0.2989\n",
      "Trail: 3, Epoch: 154, Loss: 0.3059\n",
      "Trail: 3, Epoch: 155, Loss: 0.2979\n",
      "Trail: 3, Epoch: 156, Loss: 0.3004\n",
      "Trail: 3, Epoch: 157, Loss: 0.2947\n",
      "Trail: 3, Epoch: 158, Loss: 0.3052\n",
      "Trail: 3, Epoch: 159, Loss: 0.2979\n",
      "Trail: 3, Epoch: 160, Loss: 0.2957\n",
      "Trail: 3, Epoch: 161, Loss: 0.2970\n",
      "Trail: 3, Epoch: 162, Loss: 0.3043\n",
      "Trail: 3, Epoch: 163, Loss: 0.2993\n",
      "Trail: 3, Epoch: 164, Loss: 0.3072\n",
      "Trail: 3, Epoch: 165, Loss: 0.3005\n",
      "Trail: 3, Epoch: 166, Loss: 0.3016\n",
      "Trail: 3, Epoch: 167, Loss: 0.3103\n",
      "Trail: 3, Epoch: 168, Loss: 0.3023\n",
      "Trail: 3, Epoch: 169, Loss: 0.3029\n",
      "Trail: 3, Epoch: 170, Loss: 0.2967\n",
      "Trail: 3, Epoch: 171, Loss: 0.2942\n",
      "Trail: 3, Epoch: 172, Loss: 0.2933\n",
      "Trail: 3, Epoch: 173, Loss: 0.3030\n",
      "Trail: 3, Epoch: 174, Loss: 0.2979\n",
      "Trail: 3, Epoch: 175, Loss: 0.2957\n",
      "Trail: 3, Epoch: 176, Loss: 0.2994\n",
      "Trail: 3, Epoch: 177, Loss: 0.2962\n",
      "Trail: 3, Epoch: 178, Loss: 0.2950\n",
      "Trail: 3, Epoch: 179, Loss: 0.2987\n",
      "Trail: 3, Epoch: 180, Loss: 0.3074\n",
      "Trail: 3, Epoch: 181, Loss: 0.2938\n",
      "Trail: 3, Epoch: 182, Loss: 0.3022\n",
      "Trail: 3, Epoch: 183, Loss: 0.3022\n",
      "Trail: 3, Epoch: 184, Loss: 0.3002\n",
      "Trail: 3, Epoch: 185, Loss: 0.2956\n",
      "Trail: 3, Epoch: 186, Loss: 0.2923\n",
      "Trail: 3, Epoch: 187, Loss: 0.2974\n",
      "Trail: 3, Epoch: 188, Loss: 0.3037\n",
      "Trail: 3, Epoch: 189, Loss: 0.2990\n",
      "Trail: 3, Epoch: 190, Loss: 0.3007\n",
      "Trail: 3, Epoch: 191, Loss: 0.2939\n",
      "Trail: 3, Epoch: 192, Loss: 0.2933\n",
      "Trail: 3, Epoch: 193, Loss: 0.2954\n",
      "Trail: 3, Epoch: 194, Loss: 0.2958\n",
      "Trail: 3, Epoch: 195, Loss: 0.2955\n",
      "Trail: 3, Epoch: 196, Loss: 0.2955\n",
      "Trail: 3, Epoch: 197, Loss: 0.3003\n",
      "Trail: 3, Epoch: 198, Loss: 0.2943\n",
      "Trail: 3, Epoch: 199, Loss: 0.2958\n",
      "Trail: 3, Epoch: 200, Loss: 0.2990\n",
      "[[748 137]\n",
      " [ 31  78]]\n",
      "Fscore: 0.48148148148148145 Recall: 0.7155963302752294 Precision: 0.3627906976744186 Test: 0.8309859154929577\n",
      "========end this trail==========\n",
      "========begin trail 4===========\n",
      "Trail: 4, Epoch: 00, Loss: 0.6611\n",
      "[[607 278]\n",
      " [ 11  97]]\n",
      "Fscore: 0.40165631469979296 Recall: 0.8981481481481481 Precision: 0.25866666666666666 Test: 0.6676737160120846\n",
      "Trail: 4, Epoch: 01, Loss: 0.5484\n",
      "Trail: 4, Epoch: 02, Loss: 0.5146\n",
      "Trail: 4, Epoch: 03, Loss: 0.4910\n",
      "Trail: 4, Epoch: 04, Loss: 0.4770\n",
      "Trail: 4, Epoch: 05, Loss: 0.4629\n",
      "Trail: 4, Epoch: 06, Loss: 0.4540\n",
      "Trail: 4, Epoch: 07, Loss: 0.4487\n",
      "Trail: 4, Epoch: 08, Loss: 0.4402\n",
      "Trail: 4, Epoch: 09, Loss: 0.4314\n",
      "Trail: 4, Epoch: 10, Loss: 0.4213\n",
      "Trail: 4, Epoch: 11, Loss: 0.4275\n",
      "Trail: 4, Epoch: 12, Loss: 0.4230\n",
      "Trail: 4, Epoch: 13, Loss: 0.4211\n",
      "Trail: 4, Epoch: 14, Loss: 0.4189\n",
      "Trail: 4, Epoch: 15, Loss: 0.4341\n",
      "Trail: 4, Epoch: 16, Loss: 0.4113\n",
      "Trail: 4, Epoch: 17, Loss: 0.4074\n",
      "Trail: 4, Epoch: 18, Loss: 0.4003\n",
      "Trail: 4, Epoch: 19, Loss: 0.4008\n",
      "Trail: 4, Epoch: 20, Loss: 0.3964\n",
      "Trail: 4, Epoch: 21, Loss: 0.4029\n",
      "Trail: 4, Epoch: 22, Loss: 0.3933\n",
      "Trail: 4, Epoch: 23, Loss: 0.3943\n",
      "Trail: 4, Epoch: 24, Loss: 0.3914\n",
      "Trail: 4, Epoch: 25, Loss: 0.3899\n",
      "Trail: 4, Epoch: 26, Loss: 0.3906\n",
      "Trail: 4, Epoch: 27, Loss: 0.3872\n",
      "Trail: 4, Epoch: 28, Loss: 0.3882\n",
      "Trail: 4, Epoch: 29, Loss: 0.3825\n",
      "Trail: 4, Epoch: 30, Loss: 0.3856\n",
      "Trail: 4, Epoch: 31, Loss: 0.3799\n",
      "Trail: 4, Epoch: 32, Loss: 0.3803\n",
      "Trail: 4, Epoch: 33, Loss: 0.3746\n",
      "Trail: 4, Epoch: 34, Loss: 0.3789\n",
      "Trail: 4, Epoch: 35, Loss: 0.3743\n",
      "Trail: 4, Epoch: 36, Loss: 0.3810\n",
      "Trail: 4, Epoch: 37, Loss: 0.3711\n",
      "Trail: 4, Epoch: 38, Loss: 0.3718\n",
      "Trail: 4, Epoch: 39, Loss: 0.3683\n",
      "Trail: 4, Epoch: 40, Loss: 0.3713\n",
      "Trail: 4, Epoch: 41, Loss: 0.3709\n",
      "Trail: 4, Epoch: 42, Loss: 0.3714\n",
      "Trail: 4, Epoch: 43, Loss: 0.3700\n",
      "Trail: 4, Epoch: 44, Loss: 0.3657\n",
      "Trail: 4, Epoch: 45, Loss: 0.3712\n",
      "Trail: 4, Epoch: 46, Loss: 0.3697\n",
      "Trail: 4, Epoch: 47, Loss: 0.3678\n",
      "Trail: 4, Epoch: 48, Loss: 0.3665\n",
      "Trail: 4, Epoch: 49, Loss: 0.4061\n",
      "Trail: 4, Epoch: 50, Loss: 0.3646\n",
      "[[776 109]\n",
      " [ 18  90]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fscore: 0.5863192182410424 Recall: 0.8333333333333334 Precision: 0.45226130653266333 Test: 0.8721047331319235\n",
      "Trail: 4, Epoch: 51, Loss: 0.3637\n",
      "Trail: 4, Epoch: 52, Loss: 0.3619\n",
      "Trail: 4, Epoch: 53, Loss: 0.3617\n",
      "Trail: 4, Epoch: 54, Loss: 0.3607\n",
      "Trail: 4, Epoch: 55, Loss: 0.3663\n",
      "Trail: 4, Epoch: 56, Loss: 0.3627\n",
      "Trail: 4, Epoch: 57, Loss: 0.3571\n",
      "Trail: 4, Epoch: 58, Loss: 0.3643\n",
      "Trail: 4, Epoch: 59, Loss: 0.3593\n",
      "Trail: 4, Epoch: 60, Loss: 0.3569\n",
      "Trail: 4, Epoch: 61, Loss: 0.3604\n",
      "Trail: 4, Epoch: 62, Loss: 0.3597\n",
      "Trail: 4, Epoch: 63, Loss: 0.3622\n",
      "Trail: 4, Epoch: 64, Loss: 0.3558\n",
      "Trail: 4, Epoch: 65, Loss: 0.3572\n",
      "Trail: 4, Epoch: 66, Loss: 0.3551\n",
      "Trail: 4, Epoch: 67, Loss: 0.3529\n",
      "Trail: 4, Epoch: 68, Loss: 0.3652\n",
      "Trail: 4, Epoch: 69, Loss: 0.3562\n",
      "Trail: 4, Epoch: 70, Loss: 0.3536\n",
      "Trail: 4, Epoch: 71, Loss: 0.3583\n",
      "Trail: 4, Epoch: 72, Loss: 0.3524\n",
      "Trail: 4, Epoch: 73, Loss: 0.3521\n",
      "Trail: 4, Epoch: 74, Loss: 0.3542\n",
      "Trail: 4, Epoch: 75, Loss: 0.3508\n",
      "Trail: 4, Epoch: 76, Loss: 0.3586\n",
      "Trail: 4, Epoch: 77, Loss: 0.3532\n",
      "Trail: 4, Epoch: 78, Loss: 0.3471\n",
      "Trail: 4, Epoch: 79, Loss: 0.3474\n",
      "Trail: 4, Epoch: 80, Loss: 0.3553\n",
      "Trail: 4, Epoch: 81, Loss: 0.3509\n",
      "Trail: 4, Epoch: 82, Loss: 0.3492\n",
      "Trail: 4, Epoch: 83, Loss: 0.3477\n",
      "Trail: 4, Epoch: 84, Loss: 0.3464\n",
      "Trail: 4, Epoch: 85, Loss: 0.3537\n",
      "Trail: 4, Epoch: 86, Loss: 0.3534\n",
      "Trail: 4, Epoch: 87, Loss: 0.3459\n",
      "Trail: 4, Epoch: 88, Loss: 0.3570\n",
      "Trail: 4, Epoch: 89, Loss: 0.3526\n",
      "Trail: 4, Epoch: 90, Loss: 0.3474\n",
      "Trail: 4, Epoch: 91, Loss: 0.3507\n",
      "Trail: 4, Epoch: 92, Loss: 0.3485\n",
      "Trail: 4, Epoch: 93, Loss: 0.3436\n",
      "Trail: 4, Epoch: 94, Loss: 0.3443\n",
      "Trail: 4, Epoch: 95, Loss: 0.3404\n",
      "Trail: 4, Epoch: 96, Loss: 0.3463\n",
      "Trail: 4, Epoch: 97, Loss: 0.3442\n",
      "Trail: 4, Epoch: 98, Loss: 0.3463\n",
      "Trail: 4, Epoch: 99, Loss: 0.3423\n",
      "Trail: 4, Epoch: 100, Loss: 0.3436\n",
      "[[835  50]\n",
      " [ 35  73]]\n",
      "Fscore: 0.6320346320346321 Recall: 0.6759259259259259 Precision: 0.5934959349593496 Test: 0.9144008056394763\n",
      "Trail: 4, Epoch: 101, Loss: 0.3477\n",
      "Trail: 4, Epoch: 102, Loss: 0.3429\n",
      "Trail: 4, Epoch: 103, Loss: 0.3516\n",
      "Trail: 4, Epoch: 104, Loss: 0.3456\n",
      "Trail: 4, Epoch: 105, Loss: 0.3415\n",
      "Trail: 4, Epoch: 106, Loss: 0.3467\n",
      "Trail: 4, Epoch: 107, Loss: 0.3384\n",
      "Trail: 4, Epoch: 108, Loss: 0.3393\n",
      "Trail: 4, Epoch: 109, Loss: 0.3425\n",
      "Trail: 4, Epoch: 110, Loss: 0.3389\n",
      "Trail: 4, Epoch: 111, Loss: 0.3467\n",
      "Trail: 4, Epoch: 112, Loss: 0.3390\n",
      "Trail: 4, Epoch: 113, Loss: 0.3489\n",
      "Trail: 4, Epoch: 114, Loss: 0.3350\n",
      "Trail: 4, Epoch: 115, Loss: 0.3446\n",
      "Trail: 4, Epoch: 116, Loss: 0.3353\n",
      "Trail: 4, Epoch: 117, Loss: 0.3394\n",
      "Trail: 4, Epoch: 118, Loss: 0.3423\n",
      "Trail: 4, Epoch: 119, Loss: 0.3427\n",
      "Trail: 4, Epoch: 120, Loss: 0.3339\n",
      "Trail: 4, Epoch: 121, Loss: 0.3397\n",
      "Trail: 4, Epoch: 122, Loss: 0.3444\n",
      "Trail: 4, Epoch: 123, Loss: 0.3412\n",
      "Trail: 4, Epoch: 124, Loss: 0.3400\n",
      "Trail: 4, Epoch: 125, Loss: 0.3381\n",
      "Trail: 4, Epoch: 126, Loss: 0.3388\n",
      "Trail: 4, Epoch: 127, Loss: 0.3429\n",
      "Trail: 4, Epoch: 128, Loss: 0.3405\n",
      "Trail: 4, Epoch: 129, Loss: 0.3352\n",
      "Trail: 4, Epoch: 130, Loss: 0.3389\n",
      "Trail: 4, Epoch: 131, Loss: 0.3348\n",
      "Trail: 4, Epoch: 132, Loss: 0.3363\n",
      "Trail: 4, Epoch: 133, Loss: 0.3395\n",
      "Trail: 4, Epoch: 134, Loss: 0.3372\n",
      "Trail: 4, Epoch: 135, Loss: 0.3409\n",
      "Trail: 4, Epoch: 136, Loss: 0.3312\n",
      "Trail: 4, Epoch: 137, Loss: 0.3399\n",
      "Trail: 4, Epoch: 138, Loss: 0.3374\n",
      "Trail: 4, Epoch: 139, Loss: 0.3368\n",
      "Trail: 4, Epoch: 140, Loss: 0.3274\n",
      "Trail: 4, Epoch: 141, Loss: 0.3395\n",
      "Trail: 4, Epoch: 142, Loss: 0.3431\n",
      "Trail: 4, Epoch: 143, Loss: 0.3363\n",
      "Trail: 4, Epoch: 144, Loss: 0.3340\n",
      "Trail: 4, Epoch: 145, Loss: 0.3347\n",
      "Trail: 4, Epoch: 146, Loss: 0.3301\n",
      "Trail: 4, Epoch: 147, Loss: 0.3335\n",
      "Trail: 4, Epoch: 148, Loss: 0.3356\n",
      "Trail: 4, Epoch: 149, Loss: 0.3323\n",
      "Trail: 4, Epoch: 150, Loss: 0.3322\n",
      "[[767 118]\n",
      " [ 17  91]]\n",
      "Fscore: 0.5741324921135647 Recall: 0.8425925925925926 Precision: 0.4354066985645933 Test: 0.8640483383685801\n",
      "Trail: 4, Epoch: 151, Loss: 0.3327\n",
      "Trail: 4, Epoch: 152, Loss: 0.3293\n",
      "Trail: 4, Epoch: 153, Loss: 0.3338\n",
      "Trail: 4, Epoch: 154, Loss: 0.3506\n",
      "Trail: 4, Epoch: 155, Loss: 0.3354\n",
      "Trail: 4, Epoch: 156, Loss: 0.3467\n",
      "Trail: 4, Epoch: 157, Loss: 0.3440\n",
      "Trail: 4, Epoch: 158, Loss: 0.3313\n",
      "Trail: 4, Epoch: 159, Loss: 0.3318\n",
      "Trail: 4, Epoch: 160, Loss: 0.3392\n",
      "Trail: 4, Epoch: 161, Loss: 0.3274\n",
      "Trail: 4, Epoch: 162, Loss: 0.3274\n",
      "Trail: 4, Epoch: 163, Loss: 0.3301\n",
      "Trail: 4, Epoch: 164, Loss: 0.3283\n",
      "Trail: 4, Epoch: 165, Loss: 0.3360\n",
      "Trail: 4, Epoch: 166, Loss: 0.3328\n",
      "Trail: 4, Epoch: 167, Loss: 0.3419\n",
      "Trail: 4, Epoch: 168, Loss: 0.3292\n",
      "Trail: 4, Epoch: 169, Loss: 0.3279\n",
      "Trail: 4, Epoch: 170, Loss: 0.3322\n",
      "Trail: 4, Epoch: 171, Loss: 0.3308\n",
      "Trail: 4, Epoch: 172, Loss: 0.3319\n",
      "Trail: 4, Epoch: 173, Loss: 0.3269\n",
      "Trail: 4, Epoch: 174, Loss: 0.3301\n",
      "Trail: 4, Epoch: 175, Loss: 0.3291\n",
      "Trail: 4, Epoch: 176, Loss: 0.3325\n",
      "Trail: 4, Epoch: 177, Loss: 0.3326\n",
      "Trail: 4, Epoch: 178, Loss: 0.3232\n",
      "Trail: 4, Epoch: 179, Loss: 0.3698\n",
      "Trail: 4, Epoch: 180, Loss: 0.3364\n",
      "Trail: 4, Epoch: 181, Loss: 0.3381\n",
      "Trail: 4, Epoch: 182, Loss: 0.3493\n",
      "Trail: 4, Epoch: 183, Loss: 0.3320\n",
      "Trail: 4, Epoch: 184, Loss: 0.3277\n",
      "Trail: 4, Epoch: 185, Loss: 0.3324\n",
      "Trail: 4, Epoch: 186, Loss: 0.3284\n",
      "Trail: 4, Epoch: 187, Loss: 0.3228\n",
      "Trail: 4, Epoch: 188, Loss: 0.3306\n",
      "Trail: 4, Epoch: 189, Loss: 0.3316\n",
      "Trail: 4, Epoch: 190, Loss: 0.3282\n",
      "Trail: 4, Epoch: 191, Loss: 0.3266\n",
      "Trail: 4, Epoch: 192, Loss: 0.3272\n",
      "Trail: 4, Epoch: 193, Loss: 0.3288\n",
      "Trail: 4, Epoch: 194, Loss: 0.3291\n",
      "Trail: 4, Epoch: 195, Loss: 0.3349\n",
      "Trail: 4, Epoch: 196, Loss: 0.3246\n",
      "Trail: 4, Epoch: 197, Loss: 0.3257\n",
      "Trail: 4, Epoch: 198, Loss: 0.3219\n",
      "Trail: 4, Epoch: 199, Loss: 0.3439\n",
      "Trail: 4, Epoch: 200, Loss: 0.3290\n",
      "[[782 103]\n",
      " [ 17  91]]\n",
      "Fscore: 0.6026490066225164 Recall: 0.8425925925925926 Precision: 0.4690721649484536 Test: 0.879154078549849\n",
      "========end this trail==========\n",
      "avg Accuracy   0.8332 +-  0.0295\n",
      "avg Recall    0.8125 +-  0.0530\n",
      "avg Precision    0.3843 +-  0.0446\n",
      "avg Fscore    0.5198 +-  0.0432\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #process & create the dataset files\n",
    "#     parser = argparse.ArgumentParser()\n",
    "\n",
    "#     # system\n",
    "#     parser.add_argument(\"--feature\", type=str, default=\"all\", help=\"glove | all\")\n",
    "#     #no use of user_type for now\n",
    "#     parser.add_argument(\"--user_type\", type=str, default=\"hate\", help=\"hate | suspend\")\n",
    "#     parser.add_argument(\"--model_type\", type=str, default=\"sage\", help=\"sage | gat\")\n",
    "#     parser.add_argument(\"--epoch\", type=int, default=201)\n",
    "#     args = parser.parse_args()\n",
    "    \n",
    "    args = easydict.EasyDict({\n",
    "        \"feature\": \"all\",\n",
    "        \"model_type\": \"sage\",\n",
    "        \"epoch\" : 201,\n",
    "        \"user_type\": \"hate\"\n",
    "    })\n",
    "    assert(args.feature in ['glove', 'all'])\n",
    "    assert(args.user_type in ['hate', 'suspend'])\n",
    "    assert(args.model_type in ['sage', 'gat'])\n",
    "    print(\"====information of experiment====\")\n",
    "    print(\"FEATURE: \", args.feature, \"classification_type:\", args.user_type, \"MODEL:\", args.model_type)\n",
    "    print(\"====end information of experiment====\")\n",
    "    dataset = construct_dataset(args.feature)\n",
    "    model_type = args.model_type\n",
    "    hate_index, normal_index = get_labeled_index(feature_type=args.feature)\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "    y_all = [2] * len(hate_index)\n",
    "    y_normal = [0] * len(normal_index)\n",
    "    y_all.extend(y_normal)\n",
    "    all_index = []\n",
    "    all_index.extend(hate_index)\n",
    "    all_index.extend(normal_index)\n",
    "    recall_test = []\n",
    "    accuracy_test = []\n",
    "    fscore_test = []\n",
    "    precision_test = []\n",
    "    all_index = np.array(all_index)\n",
    "    trail = 0\n",
    "    for train_i, test_i in skf.split(all_index, y_all):\n",
    "        print(\"========begin trail {:01d}===========\".format(trail))\n",
    "        all_train_index = all_index[train_i]\n",
    "        test_index = all_index[test_i]\n",
    "        data = dataset[0]\n",
    "        data.train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "        data.train_mask[all_train_index] = 1\n",
    "        data.test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "        data.test_mask[test_index] = 1\n",
    "        loader = NeighborSampler(data, size=[25], num_hops=1, batch_size=128, shuffle=True, add_self_loops=True)\n",
    "        if model_type == 'sage':\n",
    "            model = FullySupervisedGraphSageModel(data.num_features)\n",
    "        else:\n",
    "            model = FullySupervisedGATModel(data.num_features)\n",
    "        #optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-3)\n",
    "        optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=0.01)\n",
    "        #loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=True)\n",
    "        for epoch in range(args.epoch):\n",
    "            loss = train(loader, data, model, optimizer)\n",
    "            #test_acc = test(loader, data, model, data.test_mask)\n",
    "            print('Trail: {:01d}, Epoch: {:02d}, Loss: {:.4f}'.format(trail, epoch, loss))\n",
    "            if (epoch % 50 == 0):                \n",
    "                test_acc, y_pred, y_true = test(loader, data, model, data.test_mask)\n",
    "                fscore = f1_score(y_true, y_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "                recall = recall_score(y_true, y_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "                precision = precision_score(y_true, y_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "                print(confusion_matrix(y_true, y_pred))\n",
    "                print(\"Fscore:\",fscore, \"Recall:\", recall, \"Precision:\", precision, \"Test:\", test_acc)\n",
    "        model.eval()\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        correct = 0\n",
    "        for data_flow in loader(data.test_mask):\n",
    "            pred = model(data.x, data_flow).max(1)[1]\n",
    "            correct += pred.eq(data.y[data_flow.n_id]).sum().item()\n",
    "            y_pred.extend([1 if v == 2 else 0 for v in pred])\n",
    "            y_true.extend([1 if v == 2 else 0 for v in data.y[data_flow.n_id]])\n",
    "        test_acc = correct / (data.test_mask == True).sum().item()\n",
    "        fscore = f1_score(y_true, y_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "        recall = recall_score(y_true, y_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "        precision = precision_score(y_true, y_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "        accuracy_test.append(test_acc)\n",
    "        recall_test.append(recall)\n",
    "        fscore_test.append(fscore)\n",
    "        precision_test.append(precision)\n",
    "        trail+=1\n",
    "        print(\"========end this trail==========\")\n",
    "    accuracy_test = np.array(accuracy_test)\n",
    "    recall_test = np.array(recall_test)\n",
    "    fscore_test = np.array(fscore_test)\n",
    "    precision_test = np.array(precision_test)\n",
    "    print(\"avg Accuracy   %0.4f +-  %0.4f\" % (accuracy_test.mean(), accuracy_test.std()))\n",
    "    print(\"avg Recall    %0.4f +-  %0.4f\" % (recall_test.mean(), recall_test.std()))\n",
    "    print(\"avg Precision    %0.4f +-  %0.4f\" % (precision_test.mean(), precision_test.std()))\n",
    "    print(\"avg Fscore    %0.4f +-  %0.4f\" % (fscore_test.mean(), fscore_test.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
